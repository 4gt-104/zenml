{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ZenML Quickstart.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zenml-io/zenml/blob/main/examples/quickstart/Quickstart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO_v5iIaYFi2"
      },
      "source": [
        "# ZenML Quickstart Guide\n",
        "\n",
        "Our goal here is to help you to get the first practical experience with our tool and give you a brief overview on some basic functionalities of ZenML.\n",
        "\n",
        "The quickest way to get started is to create a simple pipeline. We'll be using the [MNIST](http://yann.lecun.com/exdb/mnist/) dataset (originally developed by Yann LeCun and others) digits, and then later the [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) dataset developed by Zalando.\n",
        "\n",
        "If you want to run this notebook in an interactive environment, feel free to run it in a Google Colab.\n",
        "\n",
        "## Purpose\n",
        "\n",
        "This quickstart guide is designed to provide a practical introduction to some of the main concepts and paradigms used by the ZenML framework. If you want more detail, our [full documentation](https://docs.zenml.io/) provides more on the concepts and how to implement them.\n",
        "\n",
        "## Using Google Colab\n",
        "\n",
        "You will want to use a GPU for this example. If you are following this quickstart in Google's Colab, follow these steps:\n",
        "\n",
        "- Before running anything, you need to tell Colab that you want to use a GPU. You can do this by clicking on the ‘Runtime’ tab and selecting ‘Change runtime type’. A pop-up window will open up with a drop-down menu.\n",
        "- Select ‘GPU’ from the menu and click ‘Save’.\n",
        "- It may ask if you want to restart the runtime. If so, go ahead and do that.\n",
        "\n",
        "<!-- The code for the MNIST training borrows heavily from [this](https://www.tensorflow.org/datasets/keras_example) -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNLEesHEyjkg"
      },
      "source": [
        "## Install libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7l4qDgcI_5F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed764976-0d95-4e5f-e75d-805d2bab804c"
      },
      "source": [
        "# Install the ZenML CLI tool and Tensorflow\n",
        "!pip install zenml==\"0.5.0rc2\" tensorflow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting zenml==0.5.0rc2\n",
            "  Downloading zenml-0.5.0rc2-py3-none-any.whl (121 kB)\n",
            "\u001b[K     |████████████████████████████████| 121 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.6.0)\n",
            "Collecting pydantic<2.0.0,>=1.8.2\n",
            "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 43.4 MB/s \n",
            "\u001b[?25hCollecting click<9.0.0,>=8.0.1\n",
            "  Downloading click-8.0.1-py3-none-any.whl (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 7.1 MB/s \n",
            "\u001b[?25hCollecting analytics-python<2.0.0,>=1.4.0\n",
            "  Downloading analytics_python-1.4.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting ml-pipelines-sdk<2.0.0,>=1.2.0\n",
            "  Downloading ml_pipelines_sdk-1.2.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 80.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate<0.9.0,>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from zenml==0.5.0rc2) (0.8.9)\n",
            "Collecting apache-beam<3.0.0,>=2.30.0\n",
            "  Downloading apache_beam-2.32.0-cp37-cp37m-manylinux2010_x86_64.whl (9.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.8 MB 23.6 MB/s \n",
            "\u001b[?25hCollecting gitpython<4.0.0,>=3.1.18\n",
            "  Downloading GitPython-3.1.24-py3-none-any.whl (180 kB)\n",
            "\u001b[K     |████████████████████████████████| 180 kB 70.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.8.1 in /usr/local/lib/python3.7/dist-packages (from zenml==0.5.0rc2) (2.8.2)\n",
            "Collecting panel<0.12.0,>=0.11.3\n",
            "  Downloading panel-0.11.3-py2.py3-none-any.whl (9.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.0 MB 47.7 MB/s \n",
            "\u001b[?25hCollecting pyyaml<6.0.0,>=5.4.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 56.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas<2.0.0,>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from zenml==0.5.0rc2) (1.1.5)\n",
            "Collecting distro<2.0.0,>=1.6.0\n",
            "  Downloading distro-1.6.0-py2.py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from analytics-python<2.0.0,>=1.4.0->zenml==0.5.0rc2) (1.15.0)\n",
            "Requirement already satisfied: requests<3.0,>=2.7 in /usr/local/lib/python3.7/dist-packages (from analytics-python<2.0.0,>=1.4.0->zenml==0.5.0rc2) (2.23.0)\n",
            "Collecting monotonic>=1.5\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff==1.10.0\n",
            "  Downloading backoff-1.10.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: protobuf<4,>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from apache-beam<3.0.0,>=2.30.0->zenml==0.5.0rc2) (3.17.3)\n",
            "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.7/dist-packages (from apache-beam<3.0.0,>=2.30.0->zenml==0.5.0rc2) (2018.9)\n",
            "Requirement already satisfied: typing-extensions<3.8.0,>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam<3.0.0,>=2.30.0->zenml==0.5.0rc2) (3.7.4.3)\n",
            "Requirement already satisfied: grpcio<2,>=1.29.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam<3.0.0,>=2.30.0->zenml==0.5.0rc2) (1.40.0)\n",
            "Collecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading hdfs-2.6.0-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam<3.0.0,>=2.30.0->zenml==0.5.0rc2) (3.12.0)\n",
            "Collecting dill<0.3.2,>=0.3.1.1\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[K     |████████████████████████████████| 151 kB 75.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: httplib2<0.20.0,>=0.8 in /usr/local/lib/python3.7/dist-packages (from apache-beam<3.0.0,>=2.30.0->zenml==0.5.0rc2) (0.17.4)\n",
            "Collecting orjson<4.0\n",
            "  Downloading orjson-3.6.4-cp37-cp37m-manylinux_2_24_x86_64.whl (249 kB)\n",
            "\u001b[K     |████████████████████████████████| 249 kB 68.6 MB/s \n",
            "\u001b[?25hCollecting future<1.0.0,>=0.18.2\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 56.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam<3.0.0,>=2.30.0->zenml==0.5.0rc2) (1.7)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam<3.0.0,>=2.30.0->zenml==0.5.0rc2) (1.3.0)\n",
            "Requirement already satisfied: oauth2client<5,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam<3.0.0,>=2.30.0->zenml==0.5.0rc2) (4.1.3)\n",
            "Collecting requests<3.0,>=2.7\n",
            "  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 866 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<1.21.0,>=1.14.3 in /usr/local/lib/python3.7/dist-packages (from apache-beam<3.0.0,>=2.30.0->zenml==0.5.0rc2) (1.19.5)\n",
            "Collecting fastavro<2,>=0.21.4\n",
            "  Downloading fastavro-1.4.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 58.5 MB/s \n",
            "\u001b[?25hCollecting avro-python3!=1.9.2,<1.10.0,>=1.8.1\n",
            "  Downloading avro-python3-1.9.2.1.tar.gz (37 kB)\n",
            "Requirement already satisfied: pyarrow<5.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam<3.0.0,>=2.30.0->zenml==0.5.0rc2) (3.0.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from click<9.0.0,>=8.0.1->zenml==0.5.0rc2) (4.8.1)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.7-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.8 MB/s \n",
            "\u001b[?25hCollecting smmap<5,>=3.0.1\n",
            "  Downloading smmap-4.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam<3.0.0,>=2.30.0->zenml==0.5.0rc2) (0.6.2)\n",
            "Requirement already satisfied: google-api-python-client<2,>=1.8 in /usr/local/lib/python3.7/dist-packages (from ml-pipelines-sdk<2.0.0,>=1.2.0->zenml==0.5.0rc2) (1.12.8)\n",
            "Collecting ml-metadata<1.3.0,>=1.2.0\n",
            "  Downloading ml_metadata-1.2.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 52.5 MB/s \n",
            "\u001b[?25hCollecting packaging<21,>=20\n",
            "  Downloading packaging-20.9-py2.py3-none-any.whl (40 kB)\n",
            "\u001b[K     |████████████████████████████████| 40 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py<0.13,>=0.9 in /usr/local/lib/python3.7/dist-packages (from ml-pipelines-sdk<2.0.0,>=1.2.0->zenml==0.5.0rc2) (0.12.0)\n",
            "Requirement already satisfied: portpicker<2,>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from ml-pipelines-sdk<2.0.0,>=1.2.0->zenml==0.5.0rc2) (1.3.9)\n",
            "Collecting docker<5,>=4.1\n",
            "  Downloading docker-4.4.4-py2.py3-none-any.whl (147 kB)\n",
            "\u001b[K     |████████████████████████████████| 147 kB 71.6 MB/s \n",
            "\u001b[?25hCollecting google-apitools<1,>=0.5\n",
            "  Downloading google_apitools-0.5.32-py3-none-any.whl (135 kB)\n",
            "\u001b[K     |████████████████████████████████| 135 kB 72.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jinja2<3,>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from ml-pipelines-sdk<2.0.0,>=1.2.0->zenml==0.5.0rc2) (2.11.3)\n",
            "Collecting websocket-client>=0.32.0\n",
            "  Downloading websocket_client-1.2.1-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client<2,>=1.8->ml-pipelines-sdk<2.0.0,>=1.2.0->zenml==0.5.0rc2) (3.0.1)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client<2,>=1.8->ml-pipelines-sdk<2.0.0,>=1.2.0->zenml==0.5.0rc2) (0.0.4)\n",
            "Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client<2,>=1.8->ml-pipelines-sdk<2.0.0,>=1.2.0->zenml==0.5.0rc2) (1.35.0)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client<2,>=1.8->ml-pipelines-sdk<2.0.0,>=1.2.0->zenml==0.5.0rc2) (1.26.3)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client<2,>=1.8->ml-pipelines-sdk<2.0.0,>=1.2.0->zenml==0.5.0rc2) (57.4.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client<2,>=1.8->ml-pipelines-sdk<2.0.0,>=1.2.0->zenml==0.5.0rc2) (1.53.0)\n",
            "Collecting fasteners>=0.14\n",
            "  Downloading fasteners-0.16.3-py2.py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client<2,>=1.8->ml-pipelines-sdk<2.0.0,>=1.2.0->zenml==0.5.0rc2) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client<2,>=1.8->ml-pipelines-sdk<2.0.0,>=1.2.0->zenml==0.5.0rc2) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client<2,>=1.8->ml-pipelines-sdk<2.0.0,>=1.2.0->zenml==0.5.0rc2) (0.2.8)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2<3,>=2.7.3->ml-pipelines-sdk<2.0.0,>=1.2.0->zenml==0.5.0rc2) (2.0.1)\n",
            "Collecting attrs<21,>=20.3\n",
            "  Downloading attrs-20.3.0-py2.py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 5.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client<5,>=2.0.1->apache-beam<3.0.0,>=2.30.0->zenml==0.5.0rc2) (0.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging<21,>=20->ml-pipelines-sdk<2.0.0,>=1.2.0->zenml==0.5.0rc2) (2.4.7)\n",
            "Requirement already satisfied: param>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from panel<0.12.0,>=0.11.3->zenml==0.5.0rc2) (1.11.1)\n",
            "Requirement already satisfied: bokeh<2.4.0,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from panel<0.12.0,>=0.11.3->zenml==0.5.0rc2) (2.3.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from panel<0.12.0,>=0.11.3->zenml==0.5.0rc2) (4.62.3)\n",
            "Requirement already satisfied: pyct>=0.4.4 in /usr/local/lib/python3.7/dist-packages (from panel<0.12.0,>=0.11.3->zenml==0.5.0rc2) (0.4.8)\n",
            "Requirement already satisfied: pyviz-comms>=0.7.4 in /usr/local/lib/python3.7/dist-packages (from panel<0.12.0,>=0.11.3->zenml==0.5.0rc2) (2.1.0)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.7/dist-packages (from panel<0.12.0,>=0.11.3->zenml==0.5.0rc2) (3.3.4)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.7/dist-packages (from bokeh<2.4.0,>=2.3.0->panel<0.12.0,>=0.11.3->zenml==0.5.0rc2) (7.1.2)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.7/dist-packages (from bokeh<2.4.0,>=2.3.0->panel<0.12.0,>=0.11.3->zenml==0.5.0rc2) (5.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.7->analytics-python<2.0.0,>=1.4.0->zenml==0.5.0rc2) (2021.5.30)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.7->analytics-python<2.0.0,>=1.4.0->zenml==0.5.0rc2) (2.0.6)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.7->analytics-python<2.0.0,>=1.4.0->zenml==0.5.0rc2) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.7->analytics-python<2.0.0,>=1.4.0->zenml==0.5.0rc2) (1.24.3)\n",
            "Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.6.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.6.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.6.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (5.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->click<9.0.0,>=8.0.1->zenml==0.5.0rc2) (3.5.0)\n",
            "Building wheels for collected packages: avro-python3, dill, future\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.9.2.1-py3-none-any.whl size=43512 sha256=4038dde95893a0fc10a1e57f016e16268958147ac5b81af19132d531f79f3524\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/49/5f/fdb5b9d85055c478213e0158ac122b596816149a02d82e0ab1\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78546 sha256=9f6c1a1d2d25c7365d9a372ff830af6aee4e07b0dfc730870eefd6ee294cda06\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=c5126a1932d91c711320603a16aadb388bf4eb5ca49c070e16f231ca5f23a160\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "Successfully built avro-python3 dill future\n",
            "Installing collected packages: requests, packaging, websocket-client, smmap, pyyaml, fasteners, attrs, orjson, monotonic, ml-metadata, hdfs, google-apitools, gitdb, future, fastavro, docker, dill, backoff, avro-python3, pydantic, panel, ml-pipelines-sdk, gitpython, distro, click, apache-beam, analytics-python, zenml\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 21.0\n",
            "    Uninstalling packaging-21.0:\n",
            "      Successfully uninstalled packaging-21.0\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 21.2.0\n",
            "    Uninstalling attrs-21.2.0:\n",
            "      Successfully uninstalled attrs-21.2.0\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.4\n",
            "    Uninstalling dill-0.3.4:\n",
            "      Successfully uninstalled dill-0.3.4\n",
            "  Attempting uninstall: panel\n",
            "    Found existing installation: panel 0.12.1\n",
            "    Uninstalling panel-0.12.1:\n",
            "      Successfully uninstalled panel-0.12.1\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 7.1.2\n",
            "    Uninstalling click-7.1.2:\n",
            "      Successfully uninstalled click-7.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "multiprocess 0.70.12.2 requires dill>=0.3.4, but you have dill 0.3.1.1 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n",
            "flask 1.1.4 requires click<8.0,>=5.1, but you have click 8.0.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed analytics-python-1.4.0 apache-beam-2.32.0 attrs-20.3.0 avro-python3-1.9.2.1 backoff-1.10.0 click-8.0.1 dill-0.3.1.1 distro-1.6.0 docker-4.4.4 fastavro-1.4.5 fasteners-0.16.3 future-0.18.2 gitdb-4.0.7 gitpython-3.1.24 google-apitools-0.5.32 hdfs-2.6.0 ml-metadata-1.2.0 ml-pipelines-sdk-1.2.0 monotonic-1.6 orjson-3.6.4 packaging-20.9 panel-0.11.3 pydantic-1.8.2 pyyaml-5.4.1 requests-2.26.0 smmap-4.0.0 websocket-client-1.2.1 zenml-0.5.0rc2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_RCPyaNzPy-"
      },
      "source": [
        "Once the installation is completed, you can go ahead and create your first ZenML repository for your project. As ZenML repositories are built on top of Git repositories, you can create yours in a desired empty directory through:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lcfE3l2zTU-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d3e70af-c87a-4ac9-917d-b322823431e1"
      },
      "source": [
        "# Initialize a git repository\n",
        "!git init\n",
        "\n",
        "# Initialize ZenML's .zen file\n",
        "!zenml init"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized empty Git repository in /content/.git/\n",
            "2021-10-05 09:50:54,066 — zenml.steps.base_step — DEBUG — Registering class BaseStep, bases: (), dct: {'__module__': 'zenml.steps.base_step', '__qualname__': 'BaseStep', '__doc__': 'The base implementation of a ZenML Step which will be inherited by all\\n    the other step implementations', '__init__': <function BaseStep.__init__ at 0x7fac84d86f80>, 'component': <property object at 0x7fac84c77890>, '__call__': <function BaseStep.__call__ at 0x7fac84d91440>, '__getattr__': <function BaseStep.__getattr__ at 0x7fac84c7d050>, 'process': <function BaseStep.process at 0x7fac84c7d0e0>}\n",
            "2021-10-05 09:50:54,066 — zenml.steps.base_step — DEBUG — BaseStep args: ['self']\n",
            "2021-10-05 09:50:54,152 — zenml.orchestrators — DEBUG — Airflow not installed.\n",
            "2021-10-05 09:50:54,676 — zenml.logger — DEBUG — Logging set to level: DEBUG\n",
            "2021-10-05 09:50:54,676 — zenml.logger — DEBUG — Logging set to level: DEBUG\n",
            "2021-10-05 09:50:54,676 — zenml.logger — DEBUG — Logging set to level: DEBUG\n",
            "2021-10-05 09:50:54,687 — zenml.logger — DEBUG — Logging set to level: DEBUG\n",
            "2021-10-05 09:50:54,687 — zenml.logger — DEBUG — Logging set to level: DEBUG\n",
            "2021-10-05 09:50:54,687 — zenml.logger — DEBUG — Logging set to level: DEBUG\n",
            "2021-10-05 09:50:54,688 — zenml.core.utils — DEBUG — Parsing file: /root/.config/zenml/.zenglobal.json\n",
            "2021-10-05 09:50:54,694 — zenml.utils.analytics_utils — DEBUG — Analytics opt-in: True.\n",
            "2021-10-05 09:50:54,804 — zenml.utils.analytics_utils — DEBUG — Analytics failed due to: user_id or anonymous_id must have (<class 'numbers.Number'>, (<class 'str'>,)), got: 7a9732f1-e9ab-43ee-ab36-6b036696e4cc\n",
            "Initializing at /content\n",
            "2021-10-05 09:50:54,805 — zenml.core.utils — DEBUG — Parsing file: /root/.config/zenml/.zenglobal.json\n",
            "2021-10-05 09:50:54,806 — zenml.utils.analytics_utils — DEBUG — Analytics opt-in: True.\n",
            "2021-10-05 09:50:54,806 — zenml.utils.analytics_utils — DEBUG — Analytics failed due to: user_id or anonymous_id must have (<class 'numbers.Number'>, (<class 'str'>,)), got: 7a9732f1-e9ab-43ee-ab36-6b036696e4cc\n",
            "2021-10-05 09:50:54,806 — zenml.core.utils — DEBUG — Parsing file: /root/.config/zenml/.zenglobal.json\n",
            "2021-10-05 09:50:54,809 — zenml.core.utils — DEBUG — Parsing file: /content/.zen/zenservice.json\n",
            "2021-10-05 09:50:54,809 — zenml.core.utils — DEBUG — Parsing file: /content/.zen/artifact_stores/DEFAULT.json\n",
            "2021-10-05 09:50:54,809 — zenml.core.local_service — DEBUG — Registering artifact store with key local_artifact_store, details: {'uuid': UUID('e7f1dfad-0fcb-418c-80f3-dc663bb4cc29'), 'path': '/content/.zen/local_store'}\n",
            "2021-10-05 09:50:54,811 — zenml.core.utils — DEBUG — Parsing file: /content/.zen/metadata_stores/DEFAULT.json\n",
            "2021-10-05 09:50:54,811 — zenml.core.local_service — DEBUG — Registering metadata store with key local_metadata_store, details: {'uuid': UUID('5538d516-c6df-4677-947a-496317f760ea'), 'uri': '/content/.zen/local_store/metadata.db'}\n",
            "2021-10-05 09:50:54,813 — zenml.core.utils — DEBUG — Parsing file: /content/.zen/orchestrators/DEFAULT.json\n",
            "2021-10-05 09:50:54,813 — zenml.core.local_service — DEBUG — Registering orchestrator with key local_orchestrator, details: {'uuid': UUID('ede3cd3a-ccd4-4da7-9806-9d374f275bdb')}\n",
            "2021-10-05 09:50:54,814 — zenml.core.local_service — DEBUG — Registering stack with key local_stack, details: {'stack_type': <StackTypes.base: 'base'>, 'metadata_store_name': 'local_metadata_store', 'artifact_store_name': 'local_artifact_store', 'orchestrator_name': 'local_orchestrator'}\n",
            "2021-10-05 09:50:54,815 — zenml.core.utils — DEBUG — Parsing file: /root/.config/zenml/.zenglobal.json\n",
            "ZenML repo initialized at /content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQE8PSXDzL-_"
      },
      "source": [
        "Now, the setup is completed. For the next steps, just make sure that you are executing the code within your ZenML repository."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izjbDO-6yrFM"
      },
      "source": [
        "## Import relevant packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gtj5QKCnSj0"
      },
      "source": [
        "We will use pipelines and steps in to train our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvFo9epOUE7G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42bec4a0-41f9-4560-e9a1-e139f08c4e0a"
      },
      "source": [
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from zenml.annotations import Input, Output, Step\n",
        "from zenml.artifacts import DataArtifact, ModelArtifact\n",
        "from zenml.pipelines import pipeline\n",
        "from zenml.steps import step"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-10-05 09:51:03,284 — zenml.steps.base_step — DEBUG — Registering class BaseStep, bases: (), dct: {'__module__': 'zenml.steps.base_step', '__qualname__': 'BaseStep', '__doc__': 'The base implementation of a ZenML Step which will be inherited by all\\n    the other step implementations', '__init__': <function BaseStep.__init__ at 0x7fcea59a7dd0>, 'component': <property object at 0x7fcea5848ef0>, '__call__': <function BaseStep.__call__ at 0x7fcea59b1290>, '__getattr__': <function BaseStep.__getattr__ at 0x7fcea5858e60>, 'process': <function BaseStep.process at 0x7fcea5858ef0>}\n",
            "2021-10-05 09:51:03,286 — zenml.steps.base_step — DEBUG — BaseStep args: ['self']\n",
            "2021-10-05 09:51:03,388 — zenml.orchestrators — DEBUG — Airflow not installed.\n",
            "2021-10-05 09:51:03,714 — zenml.logger — DEBUG — Logging set to level: DEBUG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UwqjAR2yvH_"
      },
      "source": [
        "## Define ZenML Steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wHcI2FinX2O"
      },
      "source": [
        "In the code that follows, you can see that we are defining the various steps of our pipeline. Each step is decorated with `@step`, the main abstraction that is currently available for creating pipeline steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZI9i2FJ0k3H"
      },
      "source": [
        "The first step is an `import` step that downloads the MNIST dataset and samples the first hundred rows for demo purposes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VT_PAW10jbp",
        "outputId": "36ecdd08-3bca-42b4-d84d-be76126840e8"
      },
      "source": [
        "@step(name=\"import_basic_mnist\")\n",
        "def ImportDataStep() -> List[float]:\n",
        "    \"\"\"Download the MNIST data store it as an artifact\"\"\"\n",
        "    (X_train, y_train), (\n",
        "        X_test,\n",
        "        y_test,\n",
        "    ) = tf.keras.datasets.mnist.load_data()\n",
        "    return [\n",
        "        X_train.tolist()[0:100],\n",
        "        y_train.tolist()[0:100],\n",
        "        X_test.tolist()[0:100],\n",
        "        y_test.tolist()[0:100],\n",
        "    ]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-10-05 09:51:07,302 — zenml.steps.base_step — DEBUG — Registering class import_basic_mnist, bases: (<class 'zenml.steps.base_step.BaseStep'>,), dct: {'process': <staticmethod object at 0x7fcea536b310>}\n",
            "2021-10-05 09:51:07,306 — zenml.steps.base_step — DEBUG — import_basic_mnist args: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AU4OSa7Z0sc0"
      },
      "source": [
        "Secondly, we normalize all images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_4bPrRB0rNy",
        "outputId": "06b150bd-e3ea-4940-c5be-f00f86331c7c"
      },
      "source": [
        "@step(name=\"normalize\")\n",
        "def NormalizeDataStep(data: Input[DataArtifact]) -> List[float]:\n",
        "    \"\"\"Normalize the values for all the images so they are between 0 and 1\"\"\"\n",
        "    import_data = data.materializers.json.read_file()\n",
        "    X_train_normed = np.array(import_data[0]) / 255.0\n",
        "    X_test_normed = np.array(import_data[2]) / 255.0\n",
        "    return [\n",
        "        X_train_normed.tolist(),\n",
        "        import_data[1],\n",
        "        X_test_normed.tolist(),\n",
        "        import_data[3],\n",
        "    ]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-10-05 09:51:08,895 — zenml.steps.base_step — DEBUG — Registering class normalize, bases: (<class 'zenml.steps.base_step.BaseStep'>,), dct: {'process': <staticmethod object at 0x7fcea4ea7250>}\n",
            "2021-10-05 09:51:08,898 — zenml.steps.base_step — DEBUG — normalize args: ['data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ma53mucU0yF3"
      },
      "source": [
        "We then add a `Trainer` step, that takes the normalized data and trains a Keras classifier on the data. Note that the `Output[ModelArtifact]` type helps in writing the model out to our artifact store. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEw7Cbqx0wXj",
        "outputId": "0603fa51-eb20-4c22-d499-9e7f1f3a972b"
      },
      "source": [
        "@step(name=\"trainer\")\n",
        "def MNISTTrainModelStep(\n",
        "    data: Input[DataArtifact],\n",
        "    model_artifact: Output[ModelArtifact],\n",
        "    epochs: int,\n",
        "):\n",
        "    \"\"\"Train a neural net from scratch to recognise MNIST digits return our\n",
        "    model or the learner\"\"\"\n",
        "    import_data = data.materializers.json.read_file()\n",
        "\n",
        "    model = tf.keras.Sequential(\n",
        "        [\n",
        "            tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "            tf.keras.layers.Dense(10, activation=\"relu\"),\n",
        "            tf.keras.layers.Dense(10),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "\n",
        "    model.fit(\n",
        "        import_data[0],\n",
        "        import_data[1],\n",
        "        epochs=epochs,\n",
        "    )\n",
        "\n",
        "    # write model\n",
        "    model_artifact.materializers.keras.write_model(model)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-10-05 09:51:12,545 — zenml.steps.base_step — DEBUG — Registering class trainer, bases: (<class 'zenml.steps.base_step.BaseStep'>,), dct: {'process': <staticmethod object at 0x7fcead86bf50>}\n",
            "2021-10-05 09:51:12,547 — zenml.steps.base_step — DEBUG — trainer args: ['data', 'model_artifact', 'epochs']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aU9ygH9s1BgR"
      },
      "source": [
        "Finally, we add an `Evaluator` step that takes as input the test set and the trained model and evaluates some final metrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37mMICD_URDW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "873fe64b-1105-4181-8541-c31356069305"
      },
      "source": [
        "@step(name=\"evaluate\")\n",
        "def EvaluateModelStep(\n",
        "    data: Input[DataArtifact], model_artifact: Input[ModelArtifact]\n",
        ") -> List[float]:\n",
        "    \"\"\"Calculate the loss for the model for each epoch in a graph\"\"\"\n",
        "    model = model_artifact.materializers.keras.read_model()\n",
        "    import_data = data.materializers.json.read_file()\n",
        "\n",
        "    test_loss, test_acc = model.evaluate(\n",
        "        import_data[2], import_data[3], verbose=2\n",
        "    )\n",
        "    return [test_loss, test_acc]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-10-05 09:51:15,271 — zenml.steps.base_step — DEBUG — Registering class evaluate, bases: (<class 'zenml.steps.base_step.BaseStep'>,), dct: {'process': <staticmethod object at 0x7fcea534fa50>}\n",
            "2021-10-05 09:51:15,272 — zenml.steps.base_step — DEBUG — evaluate args: ['data', 'model_artifact']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_iZTIz8y7Cp"
      },
      "source": [
        "## Define ZenML Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKbU3WlbnoiA"
      },
      "source": [
        "A pipeline is defined with the `@pipelines.SimplePipeline` decorator. This defines the various steps of the pipeline and specifies the dependencies between the steps, thereby determining the order in which they will be run."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rm8SIrLFWenn"
      },
      "source": [
        "# Define the pipeline\n",
        "\n",
        "@pipeline(\"mnist\")\n",
        "def MNISTTrainingPipeline(\n",
        "    import_data: Step[ImportDataStep],\n",
        "    normalize_data: Step[NormalizeDataStep],\n",
        "    trainer: Step[MNISTTrainModelStep],\n",
        "    evaluator: Step[EvaluateModelStep],\n",
        "):\n",
        "    # Link all the steps artifacts together\n",
        "    normalize_data(data=import_data.outputs.return_output)\n",
        "    trainer(data=normalize_data.outputs.return_output)\n",
        "    evaluator(\n",
        "        data=normalize_data.outputs.return_output,\n",
        "        model_artifact=trainer.outputs.model_artifact,\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-JtDHu_z1IX"
      },
      "source": [
        "## Initialise a Pipeline Run"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrJA5OSgnydC"
      },
      "source": [
        "Here we initialise a run of our `MNISTTrainingPipeline`, passing in the URI for the dataset we wish to download. In our case this is the MNIST digits dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRzZA406UVVz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d5e9967-87b7-4553-a104-b1b6602e10a6"
      },
      "source": [
        "# Initialise the pipeline\n",
        "mnist_trainer = MNISTTrainingPipeline(\n",
        "    import_data=ImportDataStep(),\n",
        "    normalize_data=NormalizeDataStep(),\n",
        "    trainer=MNISTTrainModelStep(epochs=10),\n",
        "    evaluator=EvaluateModelStep(),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-10-05 09:51:24,816 — zenml.core.utils — DEBUG — Parsing file: /content/.zen/zenservice.json\n",
            "2021-10-05 09:51:24,822 — zenml.core.utils — DEBUG — Parsing file: /root/.config/zenml/.zenglobal.json\n",
            "2021-10-05 09:51:24,825 — zenml.core.local_service — DEBUG — Fetching stack with key local_stack\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKpVG4RXz403"
      },
      "source": [
        "## Run the Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzSHv8GioAkW"
      },
      "source": [
        "Running the pipeline is as simple as calling the `run()` method on the defined pipeline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLZf7mdmUW_M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "539b9c10-a3b4-4ac3-8f44-edc1b2babe11"
      },
      "source": [
        "# Run the pipeline\n",
        "mnist_trainer.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-10-05 09:51:28,029 — zenml.core.utils — DEBUG — Parsing file: /content/.zen/zenservice.json\n",
            "2021-10-05 09:51:28,036 — zenml.core.local_service — DEBUG — Fetching orchestrator with key local_orchestrator\n",
            "2021-10-05 09:51:28,037 — zenml.utils.source_utils — DEBUG — Unpinned step found with no git sha. Attempting to load class from current repository state.\n",
            "2021-10-05 09:51:28,042 — zenml.core.utils — DEBUG — Parsing file: /content/.zen/orchestrators/ede3cd3a-ccd4-4da7-9806-9d374f275bdb.json\n",
            "2021-10-05 09:51:28,047 — zenml.core.utils — DEBUG — Parsing file: /content/.zen/zenservice.json\n",
            "2021-10-05 09:51:28,053 — zenml.core.local_service — DEBUG — Fetching artifact_store with key local_artifact_store\n",
            "2021-10-05 09:51:28,054 — zenml.utils.source_utils — DEBUG — Unpinned step found with no git sha. Attempting to load class from current repository state.\n",
            "2021-10-05 09:51:28,057 — zenml.core.utils — DEBUG — Parsing file: /content/.zen/artifact_stores/e7f1dfad-0fcb-418c-80f3-dc663bb4cc29.json\n",
            "2021-10-05 09:51:28,061 — zenml.core.utils — DEBUG — Parsing file: /content/.zen/zenservice.json\n",
            "2021-10-05 09:51:28,066 — zenml.core.local_service — DEBUG — Fetching metadata store with key local_metadata_store\n",
            "2021-10-05 09:51:28,068 — zenml.utils.source_utils — DEBUG — Unpinned step found with no git sha. Attempting to load class from current repository state.\n",
            "2021-10-05 09:51:28,071 — zenml.core.utils — DEBUG — Parsing file: /content/.zen/metadata_stores/5538d516-c6df-4677-947a-496317f760ea.json\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 1s 3ms/step - loss: 2.3565 - accuracy: 0.0900\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.2734 - accuracy: 0.1100\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.2127 - accuracy: 0.1300\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.1588 - accuracy: 0.1900\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 2.1075 - accuracy: 0.2300\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.0548 - accuracy: 0.2600\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.9978 - accuracy: 0.2800\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.9401 - accuracy: 0.3000\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.8771 - accuracy: 0.3200\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 1.8134 - accuracy: 0.3800\n",
            "INFO:tensorflow:Assets written to: /content/.zen/local_store/trainer/model_artifact/3/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-10-05 09:51:36,032 — tensorflow — INFO — Assets written to: /content/.zen/local_store/trainer/model_artifact/3/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 - 0s - loss: 1.9763 - accuracy: 0.3200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gotkJdTQz8j2"
      },
      "source": [
        "## From MNIST to Fashion MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMLU4cNW-Ei4"
      },
      "source": [
        "We got pretty good results on the MNIST model that we trained, but maybe we want to see how a similar training pipeline would work on a different dataset.\n",
        "\n",
        "You can see how easy it is to switch out one data import step and processing for another in our pipeline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIfD-3-Ms8k1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e3d0006-e788-48ff-dfba-9e0fa4b550c0"
      },
      "source": [
        "# Define a new modified import data step to download the Fashion MNIST model\n",
        "@step(name=\"import_fashion_mnist\")\n",
        "def ImportDataStep() -> List[float]:\n",
        "    \"\"\"Download the Fashion MNIST data store it as an artifact\"\"\"\n",
        "    (X_train, y_train), (\n",
        "        X_test,\n",
        "        y_test,\n",
        "    ) = tf.keras.datasets.fashion_mnist.load_data()  # CHANGING to fashion\n",
        "    return [\n",
        "        X_train.tolist()[0:100],\n",
        "        y_train.tolist()[0:100],\n",
        "        X_test.tolist()[0:100],\n",
        "        y_test.tolist()[0:100],\n",
        "    ]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-10-05 09:51:41,588 — zenml.steps.base_step — DEBUG — Registering class import_fashion_mnist, bases: (<class 'zenml.steps.base_step.BaseStep'>,), dct: {'process': <staticmethod object at 0x7fce9cbd74d0>}\n",
            "2021-10-05 09:51:41,590 — zenml.steps.base_step — DEBUG — import_fashion_mnist args: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oQO-ZGE4Kwf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2fb7281-60ee-4126-b859-b8230a1d112b"
      },
      "source": [
        "# Initialise a new pipeline\n",
        "fashion_mnist_trainer = MNISTTrainingPipeline(\n",
        "    import_data=ImportDataStep(),\n",
        "    normalize_data=NormalizeDataStep(),\n",
        "    trainer=MNISTTrainModelStep(epochs=10),\n",
        "    evaluator=EvaluateModelStep(),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-10-05 09:51:46,493 — zenml.core.utils — DEBUG — Parsing file: /content/.zen/zenservice.json\n",
            "2021-10-05 09:51:46,503 — zenml.core.utils — DEBUG — Parsing file: /root/.config/zenml/.zenglobal.json\n",
            "2021-10-05 09:51:46,508 — zenml.core.local_service — DEBUG — Fetching stack with key local_stack\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4t-KrsOfoKA4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e78731d-df35-45d3-80ab-fe6ff1be2879"
      },
      "source": [
        "# Run the new pipeline\n",
        "\n",
        "fashion_mnist_trainer.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-10-05 09:51:51,030 — zenml.core.utils — DEBUG — Parsing file: /content/.zen/zenservice.json\n",
            "2021-10-05 09:51:51,036 — zenml.core.local_service — DEBUG — Fetching orchestrator with key local_orchestrator\n",
            "2021-10-05 09:51:51,039 — zenml.utils.source_utils — DEBUG — Unpinned step found with no git sha. Attempting to load class from current repository state.\n",
            "2021-10-05 09:51:51,042 — zenml.core.utils — DEBUG — Parsing file: /content/.zen/orchestrators/ede3cd3a-ccd4-4da7-9806-9d374f275bdb.json\n",
            "2021-10-05 09:51:51,047 — zenml.core.utils — DEBUG — Parsing file: /content/.zen/zenservice.json\n",
            "2021-10-05 09:51:51,051 — zenml.core.local_service — DEBUG — Fetching artifact_store with key local_artifact_store\n",
            "2021-10-05 09:51:51,055 — zenml.utils.source_utils — DEBUG — Unpinned step found with no git sha. Attempting to load class from current repository state.\n",
            "2021-10-05 09:51:51,058 — zenml.core.utils — DEBUG — Parsing file: /content/.zen/artifact_stores/e7f1dfad-0fcb-418c-80f3-dc663bb4cc29.json\n",
            "2021-10-05 09:51:51,061 — zenml.core.utils — DEBUG — Parsing file: /content/.zen/zenservice.json\n",
            "2021-10-05 09:51:51,064 — zenml.core.local_service — DEBUG — Fetching metadata store with key local_metadata_store\n",
            "2021-10-05 09:51:51,068 — zenml.utils.source_utils — DEBUG — Unpinned step found with no git sha. Attempting to load class from current repository state.\n",
            "2021-10-05 09:51:51,070 — zenml.core.utils — DEBUG — Parsing file: /content/.zen/metadata_stores/5538d516-c6df-4677-947a-496317f760ea.json\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n",
            "Epoch 1/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.3922 - accuracy: 0.1200\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 2.1612 - accuracy: 0.2200\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 2.0184 - accuracy: 0.2800\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.9216 - accuracy: 0.3200\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.8260 - accuracy: 0.3600\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 1.7437 - accuracy: 0.3800\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.6751 - accuracy: 0.4200\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.5997 - accuracy: 0.4700\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.5419 - accuracy: 0.4800\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1.4902 - accuracy: 0.4900\n",
            "INFO:tensorflow:Assets written to: /content/.zen/local_store/trainer/model_artifact/7/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-10-05 09:51:58,158 — tensorflow — INFO — Assets written to: /content/.zen/local_store/trainer/model_artifact/7/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 - 0s - loss: 1.6853 - accuracy: 0.3300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOJtVVaFzlUO"
      },
      "source": [
        "… and that's it for the quickstart. If you came here without a hiccup, you must have successly installed ZenML, set up a ZenML repo, configured a training pipeline, executed it and evaluated the results. And, this is just the tip of the iceberg on the capabilities of ZenML.\n",
        "\n",
        "However, if you had a hiccup or you have some suggestions/questions regarding our framework, you can always check our docs or our github or even better join us on our Slack channel.\n",
        "\n",
        "Cheers!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22gkBKSntlF8"
      },
      "source": [
        "For more detailed information on all the components and steps that went into this short example, please continue reading [our more detailed documentation pages](https://docs.zenml.io/)."
      ]
    }
  ]
}