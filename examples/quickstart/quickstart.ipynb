{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63ab391a",
   "metadata": {},
   "source": [
    "# Intro to MLOps using ZenML\n",
    "\n",
    "## üåç Overview\n",
    "\n",
    "This repository is a minimalistic MLOps project intended as a starting point to learn how to put ML workflows in production. It features: \n",
    "\n",
    "- A feature engineering pipeline that loads data and prepares it for training.\n",
    "- A training pipeline that loads the preprocessed dataset and trains a model.\n",
    "- A batch inference pipeline that runs predictions on the trained model with new data.\n",
    "\n",
    "Follow along this notebook to understand how you can use ZenML to productionalize your ML workflows!\n",
    "\n",
    "<img src=\".assets/pipeline_overview.png\" width=\"50%\" alt=\"Pipelines Overview\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f466b16",
   "metadata": {},
   "source": [
    "## Run on Colab\n",
    "\n",
    "You can use Google Colab to see ZenML in action, no signup / installation\n",
    "required!\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](\n",
    "https://colab.research.google.com/github/zenml-io/zenml/blob/main/examples/quickstart/quickstart.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b2977c",
   "metadata": {},
   "source": [
    "# üë∂ Step 0. Install Requirements\n",
    "\n",
    "Let's install ZenML to get started. First we'll install the latest version of\n",
    "ZenML as well as the `sklearn` integration of ZenML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2f40eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"zenml[server]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aad397e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.environment import Environment\n",
    "\n",
    "if Environment.in_google_colab():\n",
    "    # Install Cloudflare Tunnel binary\n",
    "    !wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb && dpkg -i cloudflared-linux-amd64.deb\n",
    "\n",
    "    # Pull required modules from this example\n",
    "    !git clone -b main https://github.com/zenml-io/zenml\n",
    "    !cp -r zenml/examples/quickstart/* .\n",
    "    !rm -rf zenml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76f562e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!zenml integration install sklearn -y\n",
    "\n",
    "import IPython\n",
    "IPython.Application.instance().kernel.do_shutdown(restart=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b044374",
   "metadata": {},
   "source": [
    "Please wait for the installation to complete before running subsequent cells. At\n",
    "the end of the installation, the notebook kernel will automatically restart."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966ce581",
   "metadata": {},
   "source": [
    "## ‚òÅÔ∏è Step 1: Connect to ZenML Cloud\n",
    "\n",
    "If you are using [ZenML Cloud](https://zenml.io/cloud), execute the following\n",
    "cell with your tenant URL. Otherwise ignore.\n",
    "\n",
    "ZenML Cloud is a managed service that provides a hosted ZenML environment. It\n",
    "allows you to run your pipelines on the cloud, manage your metadata, and\n",
    "collaborate with your team. Sign up at [ZenML Cloud](https://zenml.io/cloud) for\n",
    "a free trial and to get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2587315",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenml_server_url = \"REPLACE THIS\"  # in the form \"https://URL_TO_SERVER\"\n",
    "\n",
    "!zenml connect --url $zenml_server_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081d5616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ZenML and set the default stack\n",
    "!zenml init\n",
    "\n",
    "!zenml stack set default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79f775f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the imports at the top\n",
    "from typing_extensions import Annotated\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "from zenml import step, pipeline, Model, get_step_context\n",
    "from zenml.client import Client\n",
    "from zenml.logger import get_logger\n",
    "from uuid import UUID\n",
    "\n",
    "from typing import Optional, List\n",
    "\n",
    "from zenml import pipeline\n",
    "\n",
    "from steps import (\n",
    "    data_loader,\n",
    "    data_preprocessor,\n",
    "    data_splitter,\n",
    "    model_evaluator,\n",
    "    inference_preprocessor\n",
    ")\n",
    "\n",
    "from zenml.logger import get_logger\n",
    "\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "# Initialize the ZenML client to fetch objects from the ZenML Server\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e48460",
   "metadata": {},
   "source": [
    "## ü•á Step 2: Load your data and execute feature engineering\n",
    "\n",
    "We'll start off by importing our data. In this quickstart we'll be working with\n",
    "[the Breast Cancer](https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic) dataset\n",
    "which is publicly available on the UCI Machine Learning Repository. The task is a classification\n",
    "problem, to predict whether a patient is diagnosed with breast cancer or not.\n",
    "\n",
    "When you're getting started with a machine learning problem you'll want to do\n",
    "something similar to this: import your data and get it in the right shape for\n",
    "your training. ZenML mostly gets out of your way when you're writing your Python\n",
    "code, as you'll see from the following cell.\n",
    "\n",
    "<img src=\".assets/feature_engineering_pipeline.png\" width=\"50%\" alt=\"Feature engineering pipeline\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cd974d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def data_loader_simplified(\n",
    "    random_state: int, is_inference: bool = False, target: str = \"target\"\n",
    ") -> Annotated[pd.DataFrame, \"dataset\"]:  # We name the dataset \n",
    "    \"\"\"Dataset reader step.\"\"\"\n",
    "    dataset = load_breast_cancer(as_frame=True)\n",
    "    inference_size = int(len(dataset.target) * 0.05)\n",
    "    dataset: pd.DataFrame = dataset.frame\n",
    "    inference_subset = dataset.sample(inference_size, random_state=random_state)\n",
    "    if is_inference:\n",
    "        dataset = inference_subset\n",
    "        dataset.drop(columns=target, inplace=True)\n",
    "    else:\n",
    "        dataset.drop(inference_subset.index, inplace=True)\n",
    "    dataset.reset_index(drop=True, inplace=True)\n",
    "    logger.info(f\"Dataset with {len(dataset)} records loaded!\")\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8ba4c6",
   "metadata": {},
   "source": [
    "The whole function is decorated with the `@step` decorator, which\n",
    "tells ZenML to treat this function as a step in the pipeline. This means that\n",
    "ZenML will automatically version, track, and cache the data that is produced by\n",
    "this function as an `artifact`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6286b67",
   "metadata": {},
   "source": [
    "Here is how you can call a step directly to inspect its output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d838e2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mDataset with 541 records loaded!\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "3          0.6638                  0.17300       0  \n",
       "4          0.2364                  0.07678       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data_loader_simplified(random_state=42)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c05291",
   "metadata": {},
   "source": [
    "Everything looks as we'd expect and the values are all in the right format ü•≥.\n",
    "\n",
    "We're now at the point where can bring this step (and some others) together into a single\n",
    "pipeline, the top-level organising entity for code in ZenML. Creating such a pipeline is\n",
    "as simple as adding a `@pipeline` decorator to a function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b50a9537",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline\n",
    "def feature_engineering(\n",
    "    test_size: float = 0.3,\n",
    "    drop_na: Optional[bool] = None,\n",
    "    normalize: Optional[bool] = None,\n",
    "    drop_columns: Optional[List[str]] = None,\n",
    "    target: Optional[str] = \"target\",\n",
    "    random_state: int = 17\n",
    "):\n",
    "    \"\"\"Feature engineering pipeline.\"\"\"\n",
    "    # Link all the steps together by calling them and passing the output\n",
    "    # of one step as the input of the next step.\n",
    "    raw_data = data_loader(random_state=random_state, target=target)\n",
    "    dataset_trn, dataset_tst = data_splitter(\n",
    "        dataset=raw_data,\n",
    "        test_size=test_size,\n",
    "    )\n",
    "    dataset_trn, dataset_tst, _ = data_preprocessor(\n",
    "        dataset_trn=dataset_trn,\n",
    "        dataset_tst=dataset_tst,\n",
    "        drop_na=drop_na,\n",
    "        normalize=normalize,\n",
    "        drop_columns=drop_columns,\n",
    "        target=target,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "    return dataset_trn, dataset_tst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd73c23",
   "metadata": {},
   "source": [
    "We're ready to run the pipeline now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e0aa9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mInitiating a new run for the pipeline: \u001b[0m\u001b[1;36mfeature_engineering\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mReusing registered pipeline version: \u001b[0m\u001b[1;36m(version: 39)\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mExecuting a new run.\u001b[0m\n",
      "\u001b[1;35mUsing user: \u001b[0m\u001b[1;36malexej@zenml.io\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35mUsing stack: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35m  artifact_store: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35m  orchestrator: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35mDashboard URL: https://cloud.zenml.io/organizations/fc992c14-d960-4db7-812e-8f070c99c6f0/tenants/8a462fb6-b1fe-48df-9677-edc76bc8352d/runs/502067fd-2bcf-49be-998c-38aa247bcc7f\u001b[0m\n",
      "\u001b[1;35mUsing cached version of \u001b[0m\u001b[1;36mdata_loader\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mdata_loader\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mUsing cached version of \u001b[0m\u001b[1;36mdata_splitter\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mdata_splitter\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mUsing cached version of \u001b[0m\u001b[1;36mdata_preprocessor\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mdata_preprocessor\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mPipeline run has finished in \u001b[0m\u001b[1;36m3.398s\u001b[1;35m.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pipeline_run = feature_engineering()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf34ea5",
   "metadata": {},
   "source": [
    "Click on the **Dashboard URL** in the logs above. This will let you inspect a diagram of the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1785c303",
   "metadata": {},
   "source": [
    "Let's run this again with a slightly different test size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "658c0570-2607-4b97-a72d-d45c92633e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mInitiating a new run for the pipeline: \u001b[0m\u001b[1;36mfeature_engineering\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mReusing registered pipeline version: \u001b[0m\u001b[1;36m(version: 40)\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mExecuting a new run.\u001b[0m\n",
      "\u001b[1;35mUsing user: \u001b[0m\u001b[1;36malexej@zenml.io\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35mUsing stack: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35m  artifact_store: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35m  orchestrator: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35mDashboard URL: https://cloud.zenml.io/organizations/fc992c14-d960-4db7-812e-8f070c99c6f0/tenants/8a462fb6-b1fe-48df-9677-edc76bc8352d/runs/af40ee70-8225-4b24-8f8b-57e4af62cc15\u001b[0m\n",
      "\u001b[1;35mUsing cached version of \u001b[0m\u001b[1;36mdata_loader\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mdata_loader\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mUsing cached version of \u001b[0m\u001b[1;36mdata_splitter\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mdata_splitter\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mUsing cached version of \u001b[0m\u001b[1;36mdata_preprocessor\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mdata_preprocessor\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mPipeline run has finished in \u001b[0m\u001b[1;36m4.421s\u001b[1;35m.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pipeline_run = feature_engineering(test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bb7206",
   "metadata": {},
   "source": [
    "Notice the second time around, the data loader step was **cached**, while the rest of the pipeline was rerun. \n",
    "This is because ZenML automatically determined that nothing had changed in the data loader step, \n",
    "so it didn't need to rerun it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc6849d-31ac-4c08-9ca2-cf7f5f35ccbf",
   "metadata": {},
   "source": [
    "Let's run this again with a slightly different test size and random state, to disable the cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e1d8546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mInitiating a new run for the pipeline: \u001b[0m\u001b[1;36mfeature_engineering\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mReusing registered pipeline version: \u001b[0m\u001b[1;36m(version: 41)\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mExecuting a new run.\u001b[0m\n",
      "\u001b[1;35mUsing user: \u001b[0m\u001b[1;36malexej@zenml.io\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35mUsing stack: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35m  artifact_store: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35m  orchestrator: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35mDashboard URL: https://cloud.zenml.io/organizations/fc992c14-d960-4db7-812e-8f070c99c6f0/tenants/8a462fb6-b1fe-48df-9677-edc76bc8352d/runs/6d6aac0e-231d-47ed-b703-6c39be489fec\u001b[0m\n",
      "\u001b[1;35mUsing cached version of \u001b[0m\u001b[1;36mdata_loader\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mdata_loader\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mUsing cached version of \u001b[0m\u001b[1;36mdata_splitter\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mdata_splitter\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mUsing cached version of \u001b[0m\u001b[1;36mdata_preprocessor\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mdata_preprocessor\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mPipeline run has finished in \u001b[0m\u001b[1;36m3.817s\u001b[1;35m.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pipeline_run = feature_engineering(test_size=0.25, random_state=104)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8471f93",
   "metadata": {},
   "source": [
    "We can also fetch the pipeline from the server and view the results directly in the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f208b200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_engineering-2024_04_16-07_36_57_727560\n"
     ]
    }
   ],
   "source": [
    "client = Client()\n",
    "run = client.get_pipeline(\"feature_engineering\").last_run\n",
    "print(run.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a037f09d",
   "metadata": {},
   "source": [
    "We can also see the data artifacts that were produced by the last step of the pipeline. Here's the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34283e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>12.040</td>\n",
       "      <td>28.14</td>\n",
       "      <td>76.85</td>\n",
       "      <td>449.9</td>\n",
       "      <td>0.08752</td>\n",
       "      <td>0.06000</td>\n",
       "      <td>0.023670</td>\n",
       "      <td>0.02377</td>\n",
       "      <td>0.1854</td>\n",
       "      <td>0.05698</td>\n",
       "      <td>...</td>\n",
       "      <td>33.33</td>\n",
       "      <td>87.24</td>\n",
       "      <td>567.6</td>\n",
       "      <td>0.10410</td>\n",
       "      <td>0.09726</td>\n",
       "      <td>0.05524</td>\n",
       "      <td>0.05547</td>\n",
       "      <td>0.2404</td>\n",
       "      <td>0.06639</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>9.676</td>\n",
       "      <td>13.14</td>\n",
       "      <td>64.12</td>\n",
       "      <td>272.5</td>\n",
       "      <td>0.12550</td>\n",
       "      <td>0.22040</td>\n",
       "      <td>0.118800</td>\n",
       "      <td>0.07038</td>\n",
       "      <td>0.2057</td>\n",
       "      <td>0.09575</td>\n",
       "      <td>...</td>\n",
       "      <td>18.04</td>\n",
       "      <td>69.47</td>\n",
       "      <td>328.1</td>\n",
       "      <td>0.20060</td>\n",
       "      <td>0.36630</td>\n",
       "      <td>0.29130</td>\n",
       "      <td>0.10750</td>\n",
       "      <td>0.2848</td>\n",
       "      <td>0.13640</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>10.440</td>\n",
       "      <td>15.46</td>\n",
       "      <td>66.62</td>\n",
       "      <td>329.6</td>\n",
       "      <td>0.10530</td>\n",
       "      <td>0.07722</td>\n",
       "      <td>0.006643</td>\n",
       "      <td>0.01216</td>\n",
       "      <td>0.1788</td>\n",
       "      <td>0.06450</td>\n",
       "      <td>...</td>\n",
       "      <td>19.80</td>\n",
       "      <td>73.47</td>\n",
       "      <td>395.4</td>\n",
       "      <td>0.13410</td>\n",
       "      <td>0.11530</td>\n",
       "      <td>0.02639</td>\n",
       "      <td>0.04464</td>\n",
       "      <td>0.2615</td>\n",
       "      <td>0.08269</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>12.430</td>\n",
       "      <td>17.00</td>\n",
       "      <td>78.60</td>\n",
       "      <td>477.3</td>\n",
       "      <td>0.07557</td>\n",
       "      <td>0.03454</td>\n",
       "      <td>0.013420</td>\n",
       "      <td>0.01699</td>\n",
       "      <td>0.1472</td>\n",
       "      <td>0.05561</td>\n",
       "      <td>...</td>\n",
       "      <td>20.21</td>\n",
       "      <td>81.76</td>\n",
       "      <td>515.9</td>\n",
       "      <td>0.08409</td>\n",
       "      <td>0.04712</td>\n",
       "      <td>0.02237</td>\n",
       "      <td>0.02832</td>\n",
       "      <td>0.1901</td>\n",
       "      <td>0.05932</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>14.470</td>\n",
       "      <td>24.99</td>\n",
       "      <td>95.81</td>\n",
       "      <td>656.4</td>\n",
       "      <td>0.08837</td>\n",
       "      <td>0.12300</td>\n",
       "      <td>0.100900</td>\n",
       "      <td>0.03890</td>\n",
       "      <td>0.1872</td>\n",
       "      <td>0.06341</td>\n",
       "      <td>...</td>\n",
       "      <td>31.73</td>\n",
       "      <td>113.50</td>\n",
       "      <td>808.9</td>\n",
       "      <td>0.13400</td>\n",
       "      <td>0.42020</td>\n",
       "      <td>0.40400</td>\n",
       "      <td>0.12050</td>\n",
       "      <td>0.3187</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>16.070</td>\n",
       "      <td>19.65</td>\n",
       "      <td>104.10</td>\n",
       "      <td>817.7</td>\n",
       "      <td>0.09168</td>\n",
       "      <td>0.08424</td>\n",
       "      <td>0.097690</td>\n",
       "      <td>0.06638</td>\n",
       "      <td>0.1798</td>\n",
       "      <td>0.05391</td>\n",
       "      <td>...</td>\n",
       "      <td>24.56</td>\n",
       "      <td>128.80</td>\n",
       "      <td>1223.0</td>\n",
       "      <td>0.15000</td>\n",
       "      <td>0.20450</td>\n",
       "      <td>0.28290</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.06387</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>10.510</td>\n",
       "      <td>20.19</td>\n",
       "      <td>68.64</td>\n",
       "      <td>334.2</td>\n",
       "      <td>0.11220</td>\n",
       "      <td>0.13030</td>\n",
       "      <td>0.064760</td>\n",
       "      <td>0.03068</td>\n",
       "      <td>0.1922</td>\n",
       "      <td>0.07782</td>\n",
       "      <td>...</td>\n",
       "      <td>22.75</td>\n",
       "      <td>72.62</td>\n",
       "      <td>374.4</td>\n",
       "      <td>0.13000</td>\n",
       "      <td>0.20490</td>\n",
       "      <td>0.12950</td>\n",
       "      <td>0.06136</td>\n",
       "      <td>0.2383</td>\n",
       "      <td>0.09026</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>14.410</td>\n",
       "      <td>19.73</td>\n",
       "      <td>96.03</td>\n",
       "      <td>651.0</td>\n",
       "      <td>0.08757</td>\n",
       "      <td>0.16760</td>\n",
       "      <td>0.136200</td>\n",
       "      <td>0.06602</td>\n",
       "      <td>0.1714</td>\n",
       "      <td>0.07192</td>\n",
       "      <td>...</td>\n",
       "      <td>22.13</td>\n",
       "      <td>101.70</td>\n",
       "      <td>767.3</td>\n",
       "      <td>0.09983</td>\n",
       "      <td>0.24720</td>\n",
       "      <td>0.22200</td>\n",
       "      <td>0.10210</td>\n",
       "      <td>0.2272</td>\n",
       "      <td>0.08799</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>27.420</td>\n",
       "      <td>26.27</td>\n",
       "      <td>186.90</td>\n",
       "      <td>2501.0</td>\n",
       "      <td>0.10840</td>\n",
       "      <td>0.19880</td>\n",
       "      <td>0.363500</td>\n",
       "      <td>0.16890</td>\n",
       "      <td>0.2061</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>31.37</td>\n",
       "      <td>251.20</td>\n",
       "      <td>4254.0</td>\n",
       "      <td>0.13570</td>\n",
       "      <td>0.42560</td>\n",
       "      <td>0.68330</td>\n",
       "      <td>0.26250</td>\n",
       "      <td>0.2641</td>\n",
       "      <td>0.07427</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>22.270</td>\n",
       "      <td>19.67</td>\n",
       "      <td>152.80</td>\n",
       "      <td>1509.0</td>\n",
       "      <td>0.13260</td>\n",
       "      <td>0.27680</td>\n",
       "      <td>0.426400</td>\n",
       "      <td>0.18230</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>...</td>\n",
       "      <td>28.01</td>\n",
       "      <td>206.80</td>\n",
       "      <td>2360.0</td>\n",
       "      <td>0.17010</td>\n",
       "      <td>0.69970</td>\n",
       "      <td>0.96080</td>\n",
       "      <td>0.29100</td>\n",
       "      <td>0.4055</td>\n",
       "      <td>0.09789</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>405 rows √ó 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "444       12.040         28.14           76.85      449.9          0.08752   \n",
       "478        9.676         13.14           64.12      272.5          0.12550   \n",
       "210       10.440         15.46           66.62      329.6          0.10530   \n",
       "299       12.430         17.00           78.60      477.3          0.07557   \n",
       "513       14.470         24.99           95.81      656.4          0.08837   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "71        16.070         19.65          104.10      817.7          0.09168   \n",
       "106       10.510         20.19           68.64      334.2          0.11220   \n",
       "270       14.410         19.73           96.03      651.0          0.08757   \n",
       "435       27.420         26.27          186.90     2501.0          0.10840   \n",
       "102       22.270         19.67          152.80     1509.0          0.13260   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "444           0.06000        0.023670              0.02377         0.1854   \n",
       "478           0.22040        0.118800              0.07038         0.2057   \n",
       "210           0.07722        0.006643              0.01216         0.1788   \n",
       "299           0.03454        0.013420              0.01699         0.1472   \n",
       "513           0.12300        0.100900              0.03890         0.1872   \n",
       "..                ...             ...                  ...            ...   \n",
       "71            0.08424        0.097690              0.06638         0.1798   \n",
       "106           0.13030        0.064760              0.03068         0.1922   \n",
       "270           0.16760        0.136200              0.06602         0.1714   \n",
       "435           0.19880        0.363500              0.16890         0.2061   \n",
       "102           0.27680        0.426400              0.18230         0.2556   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "444                 0.05698  ...          33.33            87.24       567.6   \n",
       "478                 0.09575  ...          18.04            69.47       328.1   \n",
       "210                 0.06450  ...          19.80            73.47       395.4   \n",
       "299                 0.05561  ...          20.21            81.76       515.9   \n",
       "513                 0.06341  ...          31.73           113.50       808.9   \n",
       "..                      ...  ...            ...              ...         ...   \n",
       "71                  0.05391  ...          24.56           128.80      1223.0   \n",
       "106                 0.07782  ...          22.75            72.62       374.4   \n",
       "270                 0.07192  ...          22.13           101.70       767.3   \n",
       "435                 0.05623  ...          31.37           251.20      4254.0   \n",
       "102                 0.07039  ...          28.01           206.80      2360.0   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "444           0.10410            0.09726          0.05524   \n",
       "478           0.20060            0.36630          0.29130   \n",
       "210           0.13410            0.11530          0.02639   \n",
       "299           0.08409            0.04712          0.02237   \n",
       "513           0.13400            0.42020          0.40400   \n",
       "..                ...                ...              ...   \n",
       "71            0.15000            0.20450          0.28290   \n",
       "106           0.13000            0.20490          0.12950   \n",
       "270           0.09983            0.24720          0.22200   \n",
       "435           0.13570            0.42560          0.68330   \n",
       "102           0.17010            0.69970          0.96080   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  target  \n",
       "444               0.05547          0.2404                  0.06639       1  \n",
       "478               0.10750          0.2848                  0.13640       1  \n",
       "210               0.04464          0.2615                  0.08269       1  \n",
       "299               0.02832          0.1901                  0.05932       1  \n",
       "513               0.12050          0.3187                  0.10230       1  \n",
       "..                    ...             ...                      ...     ...  \n",
       "71                0.15200          0.2650                  0.06387       0  \n",
       "106               0.06136          0.2383                  0.09026       1  \n",
       "270               0.10210          0.2272                  0.08799       1  \n",
       "435               0.26250          0.2641                  0.07427       0  \n",
       "102               0.29100          0.4055                  0.09789       0  \n",
       "\n",
       "[405 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read one of the datasets. This is the one with a 0.25 test split\n",
    "run.steps[\"data_preprocessor\"].outputs[\"dataset_trn\"].load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c28b474",
   "metadata": {},
   "source": [
    "# ‚åö Step 3: Training pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87909827",
   "metadata": {},
   "source": [
    "Now that we have our data it makes sense to train some models with it. \n",
    "\n",
    "We'll start with two simple models, a SGD Classifier and a Random Forest\n",
    "Classifier. We'll train them both on the same data and then compare their performance.\n",
    "\n",
    "<img src=\".assets/training_pipeline.png\" width=\"50%\" alt=\"Training pipeline\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fccf1bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from typing_extensions import Annotated\n",
    "from zenml import ArtifactConfig, step\n",
    "from zenml.logger import get_logger\n",
    "from zenml import Model\n",
    "\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "\n",
    "@step(enable_cache=False)\n",
    "def model_trainer(\n",
    "    dataset_trn: pd.DataFrame,\n",
    "    model_type: str = \"sgd\",\n",
    ") -> Annotated[ClassifierMixin, ArtifactConfig(name=\"sklearn_classifier\", is_model_artifact=True)]:\n",
    "    \"\"\"Configure and train a model on the training dataset.\"\"\"\n",
    "    target = \"target\"\n",
    "    if model_type == \"sgd\":\n",
    "        model = SGDClassifier()\n",
    "    elif model_type == \"rf\":\n",
    "        model = RandomForestClassifier()\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model type {model_type}\")   \n",
    "\n",
    "    logger.info(f\"Training {model_type} model {model}...\")\n",
    "\n",
    "    model.fit(\n",
    "        dataset_trn.drop(columns=[target]),\n",
    "        dataset_trn[target],\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f22174",
   "metadata": {},
   "source": [
    "And here's the pipeline that uses the training step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1aa98f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline\n",
    "def training(\n",
    "    model_type: str = \"sgd\",\n",
    "    min_train_accuracy: float = 0.0,\n",
    "    min_test_accuracy: float = 0.0,\n",
    "):\n",
    "    \"\"\"Model training pipeline.\"\"\" \n",
    "    dataset_trn, dataset_tst = feature_engineering()\n",
    "\n",
    "    trained_model = model_trainer(\n",
    "        dataset_trn=dataset_trn,\n",
    "        model_type=model_type,\n",
    "    )\n",
    "\n",
    "    model_evaluator(\n",
    "        model=trained_model,\n",
    "        dataset_trn=dataset_trn,\n",
    "        dataset_tst=dataset_tst,\n",
    "        min_train_accuracy=min_train_accuracy,\n",
    "        min_test_accuracy=min_test_accuracy,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd4dc8e",
   "metadata": {},
   "source": [
    "We want to end up tracking the models created by this pipeline. For this we'll create an instance of a ZenML Model and attach it to pipeline settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fb92f600",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_settings= {\n",
    "    \"model\": Model(\n",
    "        name=\"sklearn_breast_cancer_classifier\",\n",
    "        description=\"A breast cancer classifier\",\n",
    "        tags=[\"breast_cancer\", \"classifier\"])\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b70fd3",
   "metadata": {},
   "source": [
    "The end goal of this quick baseline evaluation is to understand which of the two\n",
    "models performs better. We'll use the `evaluator` step to compare the two\n",
    "models. This step takes in the model from the trainer step, and computes its score\n",
    "over the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c64885ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mInitiating a new run for the pipeline: \u001b[0m\u001b[1;36mtraining\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mReusing registered pipeline version: \u001b[0m\u001b[1;36m(version: 236)\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mNew model \u001b[0m\u001b[1;36msklearn_breast_cancer_classifier\u001b[1;35m was created implicitly.\u001b[0m\n",
      "\u001b[1;35mNew model version \u001b[0m\u001b[1;36mrf\u001b[1;35m was created.\u001b[0m\n",
      "\u001b[1;35mDashboard URL for Model Version with name rf : https://cloud.zenml.io/organizations/fc992c14-d960-4db7-812e-8f070c99c6f0/tenants/8a462fb6-b1fe-48df-9677-edc76bc8352d/model-versions/c3bac213-b468-4361-8155-ac50ba8645bf\u001b[0m\n",
      "\u001b[1;35mExecuting a new run.\u001b[0m\n",
      "\u001b[1;35mUsing user: \u001b[0m\u001b[1;36malexej@zenml.io\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35mUsing stack: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35m  artifact_store: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35m  orchestrator: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35mDashboard URL: https://cloud.zenml.io/organizations/fc992c14-d960-4db7-812e-8f070c99c6f0/tenants/8a462fb6-b1fe-48df-9677-edc76bc8352d/runs/e4ecf9e5-f308-4e3a-8d9d-0c3964e911b5\u001b[0m\n",
      "\u001b[1;35mUsing cached version of \u001b[0m\u001b[1;36mdata_loader\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mdata_loader\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mUsing cached version of \u001b[0m\u001b[1;36mdata_splitter\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mdata_splitter\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mUsing cached version of \u001b[0m\u001b[1;36mdata_preprocessor\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mdata_preprocessor\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mCaching \u001b[0m\u001b[1;36mdisabled\u001b[1;35m explicitly for \u001b[0m\u001b[1;36mmodel_trainer\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mmodel_trainer\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mTraining rf model RandomForestClassifier()...\u001b[0m\n",
      "\u001b[1;35mTraining rf model RandomForestClassifier()...\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mmodel_trainer\u001b[1;35m has finished in \u001b[0m\u001b[1;36m5.944s\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mmodel_evaluator\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mTrain accuracy=100.00%\u001b[0m\n",
      "\u001b[1;35mTest accuracy=96.93%\u001b[0m\n",
      "\u001b[1;35mImplicitly linking artifact \u001b[0m\u001b[1;36moutput\u001b[1;35m to model \u001b[0m\u001b[1;36msklearn_breast_cancer_classifier\u001b[1;35m version \u001b[0m\u001b[1;36mrf\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mmodel_evaluator\u001b[1;35m has finished in \u001b[0m\u001b[1;36m5.336s\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mPipeline run has finished in \u001b[0m\u001b[1;36m24.570s\u001b[1;35m.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Lets add some metadata to the model to make it identifiable\n",
    "pipeline_settings[\"model\"].version = \"rf\"\n",
    "    \n",
    "training.with_options(**pipeline_settings)(model_type=\"rf\")\n",
    "\n",
    "rf_run = client.get_pipeline(\"training\").last_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4300c82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mInitiating a new run for the pipeline: \u001b[0m\u001b[1;36mtraining\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mReusing registered pipeline version: \u001b[0m\u001b[1;36m(version: 237)\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mNew model version \u001b[0m\u001b[1;36msgd\u001b[1;35m was created.\u001b[0m\n",
      "\u001b[1;35mDashboard URL for Model Version with name sgd : https://cloud.zenml.io/organizations/fc992c14-d960-4db7-812e-8f070c99c6f0/tenants/8a462fb6-b1fe-48df-9677-edc76bc8352d/model-versions/62d39b93-04d2-44f8-9bc4-4f62eadf949e\u001b[0m\n",
      "\u001b[1;35mExecuting a new run.\u001b[0m\n",
      "\u001b[1;35mUsing user: \u001b[0m\u001b[1;36malexej@zenml.io\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35mUsing stack: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35m  artifact_store: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35m  orchestrator: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35mDashboard URL: https://cloud.zenml.io/organizations/fc992c14-d960-4db7-812e-8f070c99c6f0/tenants/8a462fb6-b1fe-48df-9677-edc76bc8352d/runs/57596481-ee53-45fe-aa65-6d834191bc60\u001b[0m\n",
      "\u001b[1;35mUsing cached version of \u001b[0m\u001b[1;36mdata_loader\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mdata_loader\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mUsing cached version of \u001b[0m\u001b[1;36mdata_splitter\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mdata_splitter\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mUsing cached version of \u001b[0m\u001b[1;36mdata_preprocessor\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mdata_preprocessor\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mCaching \u001b[0m\u001b[1;36mdisabled\u001b[1;35m explicitly for \u001b[0m\u001b[1;36mmodel_trainer\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mmodel_trainer\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mTraining sgd model SGDClassifier()...\u001b[0m\n",
      "\u001b[1;35mTraining sgd model SGDClassifier()...\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mmodel_trainer\u001b[1;35m has finished in \u001b[0m\u001b[1;36m5.325s\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mmodel_evaluator\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mTrain accuracy=91.01%\u001b[0m\n",
      "\u001b[1;35mTest accuracy=91.41%\u001b[0m\n",
      "\u001b[1;35mImplicitly linking artifact \u001b[0m\u001b[1;36moutput\u001b[1;35m to model \u001b[0m\u001b[1;36msklearn_breast_cancer_classifier\u001b[1;35m version \u001b[0m\u001b[1;36msgd\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mmodel_evaluator\u001b[1;35m has finished in \u001b[0m\u001b[1;36m5.027s\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mPipeline run has finished in \u001b[0m\u001b[1;36m22.328s\u001b[1;35m.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Use a SGD classifier\n",
    "pipeline_settings[\"model\"].version = \"sgd\"\n",
    "\n",
    "sgd_run = training.with_options(**pipeline_settings)(model_type=\"sgd\")\n",
    "\n",
    "sgd_run = client.get_pipeline(\"training\").last_run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f1a68a",
   "metadata": {},
   "source": [
    "You can see from the logs already how our model training went: the\n",
    "`RandomForestClassifier` performed considerably better than the `SGDClassifier`.\n",
    "We can compare the two pipeline runs explicitely. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d95810b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The evaluator returns a float value with the accuracy\n",
    "rf_run.steps[\"model_evaluator\"].output.load() > sgd_run.steps[\"model_evaluator\"].output.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e256d145",
   "metadata": {},
   "source": [
    "# üíØ Step 4: Inspecting the models produced by your pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09597223",
   "metadata": {},
   "source": [
    "This time, running both pipelines has created two associated **model versions**.\n",
    "You can list your ZenML model and their versions as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fbb25913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "body=ModelResponseBody(created=datetime.datetime(2024, 4, 16, 8, 17, 40), updated=datetime.datetime(2024, 4, 16, 8, 17, 40), user=UserResponse(body=UserResponseBody(created=datetime.datetime(2023, 10, 23, 15, 36, 12), updated=datetime.datetime(2024, 4, 16, 4, 52, 13), active=True, activation_token=None, full_name='Alexej Penner', email_opted_in=True, is_service_account=False, is_admin=False), metadata=None, resources=None, id=UUID('ac044541-bcb1-4f33-b41e-5c60a3f39485'), permission_denied=False, name='alexej@zenml.io'), tags=[TagResponse(body=TagResponseBody(created=datetime.datetime(2023, 12, 12, 15, 8, 29), updated=datetime.datetime(2023, 12, 12, 15, 8, 29), color=<ColorVariants.ORANGE: 'orange'>, tagged_count=88), metadata=None, resources=None, id=UUID('469b1284-df0a-4fee-b247-d80915501fb8'), permission_denied=False, name='breast_cancer'), TagResponse(body=TagResponseBody(created=datetime.datetime(2023, 12, 12, 15, 8, 29), updated=datetime.datetime(2023, 12, 12, 15, 8, 29), color=<ColorVariants.PURPLE: 'purple'>, tagged_count=88), metadata=None, resources=None, id=UUID('dad60bad-aeda-42fc-8108-a49e0b451b34'), permission_denied=False, name='classifier')], latest_version_name='sgd', latest_version_id=UUID('62d39b93-04d2-44f8-9bc4-4f62eadf949e'), workspace={'body': {'created': '2023-10-23T15:34:47', 'updated': '2023-10-23T15:34:47'}, 'metadata': None, 'resources': None, 'id': 'f3a544f2-afb5-4672-934a-7a465c66201c', 'permission_denied': False, 'name': 'default'}) metadata=ModelResponseMetadata(workspace=WorkspaceResponse(body=WorkspaceResponseBody(created=datetime.datetime(2023, 10, 23, 15, 34, 47), updated=datetime.datetime(2023, 10, 23, 15, 34, 47)), metadata=None, resources=None, id=UUID('f3a544f2-afb5-4672-934a-7a465c66201c'), permission_denied=False, name='default'), license=None, description='A breast cancer classifier', audience=None, use_cases=None, limitations=None, trade_offs=None, ethics=None, save_models_to_registry=True) resources=None id=UUID('29b4ed12-1530-4072-a4e7-9ddfa676b012') permission_denied=False name='sklearn_breast_cancer_classifier'\n",
      "Model sklearn_breast_cancer_classifier has 2 versions\n"
     ]
    }
   ],
   "source": [
    "zenml_model = client.get_model(\"sklearn_breast_cancer_classifier\")\n",
    "print(zenml_model)\n",
    "\n",
    "number_of_versions = client.list_model_versions(model_name_or_id=zenml_model.id).total\n",
    "\n",
    "print(f\"Model {zenml_model.name} has {number_of_versions} versions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82cfac2",
   "metadata": {},
   "source": [
    "The interesting part is that ZenML linked all artifacts produced by the\n",
    "pipelines to that model version, including the two pickle files that represent our\n",
    "SGD and RandomForest classifier. We can see all artifacts directly from the model\n",
    "version object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "31211413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's load the RF version\n",
    "rf_zenml_model_version = client.get_model_version(\"breast_cancer_classifier\", \"rf\")\n",
    "\n",
    "# We can now load our classifier directly as well\n",
    "random_forest_classifier = rf_zenml_model_version.get_artifact(\"sklearn_classifier\").load()\n",
    "\n",
    "random_forest_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53517a9a",
   "metadata": {},
   "source": [
    "If you are a [ZenML Cloud](https://zenml.io/cloud) user, you can see all of this visualized in the dashboard:\n",
    "\n",
    "<img src=\".assets/cloud_mcp_screenshot.png\" width=\"70%\" alt=\"Model Control Plane\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb645dde",
   "metadata": {},
   "source": [
    "There is a lot more you can do with ZenML models, including the ability to\n",
    "track metrics by adding metadata to it, or having them persist in a model\n",
    "registry. However, these topics can be explored more in the\n",
    "[ZenML docs](https://docs.zenml.io).\n",
    "\n",
    "For now, we will use the ZenML model control plane to promote our best\n",
    "model to `production`. You can do this by simply setting the `stage` of\n",
    "your chosen model version to the `production` tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "26b718f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set our best classifier to production\n",
    "rf_zenml_model_version.set_stage(\"production\", force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fddf3d0",
   "metadata": {},
   "source": [
    "Of course, normally one would only promote the model by comparing to all other model\n",
    "versions and doing some other tests. But that's a bit more advanced use-case. See the\n",
    "[e2e_batch example](https://github.com/zenml-io/zenml/tree/main/examples/e2e) to get\n",
    "more insight into that sort of flow!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecbc8cf",
   "metadata": {},
   "source": [
    "<img src=\".assets/cloud_mcp.png\" width=\"60%\" alt=\"Model Control Plane\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1146db",
   "metadata": {},
   "source": [
    "Once the model is promoted, we can now consume the right model version in our\n",
    "batch inference pipeline directly. Let's see how that works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6306f14",
   "metadata": {},
   "source": [
    "# ü´Ö Step 5: Consuming the model in production"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51f3108",
   "metadata": {},
   "source": [
    "The batch inference pipeline simply takes the model marked as `production` and runs inference on it\n",
    "with `live data`. The critical step here is the `inference_predict` step, where we load the model in memory\n",
    "and generate predictions:\n",
    "\n",
    "<img src=\".assets/inference_pipeline.png\" width=\"45%\" alt=\"Inference pipeline\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "92c4c7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def inference_predict(dataset_inf: pd.DataFrame) -> Annotated[pd.Series, \"predictions\"]:\n",
    "    \"\"\"Predictions step\"\"\"\n",
    "    # Get the model\n",
    "    model = get_step_context().model\n",
    "\n",
    "    # run prediction from memory\n",
    "    predictor = model.load_artifact(\"sklearn_classifier\")\n",
    "    predictions = predictor.predict(dataset_inf)\n",
    "\n",
    "    predictions = pd.Series(predictions, name=\"predicted\")\n",
    "\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aeb227b",
   "metadata": {},
   "source": [
    "Apart from the loading the model, we must also load the preprocessing pipeline that we ran in feature engineering,\n",
    "so that we can do the exact steps that we did on training time, in inference time. Let's bring it all together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "37c409bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline\n",
    "def inference(preprocess_pipeline_id: UUID):\n",
    "    \"\"\"Model batch inference pipeline\"\"\"\n",
    "    # random_state = client.get_artifact_version(name_id_or_prefix=preprocess_pipeline_id).metadata[\"random_state\"].value\n",
    "    # target = client.get_artifact_version(name_id_or_prefix=preprocess_pipeline_id).run_metadata['target'].value\n",
    "    random_state = 42\n",
    "    target = \"target\"\n",
    "\n",
    "    df_inference = data_loader(\n",
    "        random_state=random_state, is_inference=True\n",
    "    )\n",
    "    df_inference = inference_preprocessor(\n",
    "        dataset_inf=df_inference,\n",
    "        # We use the preprocess pipeline from the feature engineering pipeline\n",
    "        preprocess_pipeline=client.get_artifact_version(name_id_or_prefix=preprocess_pipeline_id),\n",
    "        target=target,\n",
    "    )\n",
    "    inference_predict(\n",
    "        dataset_inf=df_inference,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7afe7be",
   "metadata": {},
   "source": [
    "The way to load the right model is to pass in the `production` stage into the `Model` config this time.\n",
    "This will ensure to always load the production model, decoupled from all other pipelines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "61bf5939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m\u001b[0m\u001b[1;36mversion\u001b[1;35m \u001b[0m\u001b[1;36mproduction\u001b[1;35m matches one of the possible \u001b[0m\u001b[1;36mModelStages\u001b[1;35m and will be fetched using stage.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pipeline_settings = {\"enable_cache\": False}\n",
    "\n",
    "# Lets add some metadata to the model to make it identifiable\n",
    "pipeline_settings[\"model\"] = Model(\n",
    "    name=\"breast_cancer_classifier\",\n",
    "    version=\"production\", # We can pass in the stage name here!\n",
    "    license=\"Apache 2.0\",\n",
    "    description=\"A breast cancer classifier\",\n",
    "    tags=[\"breast_cancer\", \"classifier\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ff3402f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mInitiating a new run for the pipeline: \u001b[0m\u001b[1;36minference\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mRegistered new version: \u001b[0m\u001b[1;36m(version 28)\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mExecuting a new run.\u001b[0m\n",
      "\u001b[1;35mCaching is disabled by default for \u001b[0m\u001b[1;36minference\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mUsing user: \u001b[0m\u001b[1;36malexej@zenml.io\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35mUsing stack: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35m  artifact_store: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35m  orchestrator: \u001b[0m\u001b[1;36mdefault\u001b[1;35m\u001b[0m\n",
      "\u001b[1;35mDashboard URL: https://cloud.zenml.io/organizations/fc992c14-d960-4db7-812e-8f070c99c6f0/tenants/8a462fb6-b1fe-48df-9677-edc76bc8352d/runs/fd586f63-8cd5-40f8-bf26-af1ab911e3dd\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mdata_loader\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mDataset with 28 records loaded!\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36mdata_loader\u001b[1;35m has finished in \u001b[0m\u001b[1;36m6.992s\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36minference_preprocessor\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36minference_preprocessor\u001b[1;35m has finished in \u001b[0m\u001b[1;36m6.494s\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36minference_predict\u001b[1;35m has started.\u001b[0m\n",
      "\u001b[33mYou specified both an ID as well as a version of the artifact_versions. Ignoring the version and fetching the artifact_versions by ID.\u001b[0m\n",
      "\u001b[1;35mStep \u001b[0m\u001b[1;36minference_predict\u001b[1;35m has finished in \u001b[0m\u001b[1;36m9.356s\u001b[1;35m.\u001b[0m\n",
      "\u001b[1;35mPipeline run has finished in \u001b[0m\u001b[1;36m24.845s\u001b[1;35m.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PipelineRunResponse(body=PipelineRunResponseBody(created=datetime.datetime(2024, 4, 16, 8, 26, 13), updated=datetime.datetime(2024, 4, 16, 8, 26, 13), user=UserResponse(body=UserResponseBody(created=datetime.datetime(2023, 10, 23, 15, 36, 12), updated=datetime.datetime(2024, 4, 16, 4, 52, 13), active=True, activation_token=None, full_name='Alexej Penner', email_opted_in=True, is_service_account=False, is_admin=False), metadata=None, resources=None, id=UUID('ac044541-bcb1-4f33-b41e-5c60a3f39485'), permission_denied=False, name='alexej@zenml.io'), status=<ExecutionStatus.INITIALIZING: 'initializing'>, stack=StackResponse(body=StackResponseBody(created=datetime.datetime(2023, 11, 30, 9, 39, 29), updated=datetime.datetime(2023, 11, 30, 9, 39, 29), user=None), metadata=None, resources=None, id=UUID('a4cd4161-6ee5-411c-8adf-559ac084ceb5'), permission_denied=False, name='default'), pipeline=PipelineResponse(body=PipelineResponseBody(created=datetime.datetime(2024, 4, 16, 8, 26, 11), updated=datetime.datetime(2024, 4, 16, 8, 26, 11), user=UserResponse(body=UserResponseBody(created=datetime.datetime(2023, 10, 23, 15, 36, 12), updated=datetime.datetime(2024, 4, 16, 4, 52, 13), active=True, activation_token=None, full_name='Alexej Penner', email_opted_in=True, is_service_account=False, is_admin=False), metadata=None, resources=None, id=UUID('ac044541-bcb1-4f33-b41e-5c60a3f39485'), permission_denied=False, name='alexej@zenml.io'), status=[<ExecutionStatus.INITIALIZING: 'initializing'>], version='28'), metadata=None, resources=None, id=UUID('d626e292-e696-41f0-8133-1eab97a7787f'), permission_denied=False, name='inference'), build=None, schedule=None, code_reference=None, deployment_id=UUID('4a117d9c-ef5f-43aa-9646-d3893ff976a2'), trigger_execution=None), metadata=PipelineRunResponseMetadata(workspace=WorkspaceResponse(body=WorkspaceResponseBody(created=datetime.datetime(2023, 10, 23, 15, 34, 47), updated=datetime.datetime(2023, 10, 23, 15, 34, 47)), metadata=None, resources=None, id=UUID('f3a544f2-afb5-4672-934a-7a465c66201c'), permission_denied=False, name='default'), run_metadata={}, steps={}, config=PipelineConfiguration(enable_cache=False, enable_artifact_metadata=None, enable_artifact_visualization=None, enable_step_logs=None, settings={}, extra={}, failure_hook_source=None, success_hook_source=None, model=Model(name='breast_cancer_classifier', license='Apache 2.0', description='A breast cancer classifier', audience=None, use_cases=None, limitations=None, trade_offs=None, ethics=None, tags=['breast_cancer', 'classifier'], version='production', save_models_to_registry=True, suppress_class_validation_warnings=True, was_created_in_this_run=False), parameters=None, name='inference'), start_time=datetime.datetime(2024, 4, 16, 8, 26, 13), end_time=None, client_environment={'environment': 'notebook', 'os': 'linux', 'linux_distro': 'ubuntu', 'linux_distro_like': 'debian', 'linux_distro_version': '20.04', 'python_version': '3.10.4'}, orchestrator_environment={}, orchestrator_run_id=None), resources=None, id=UUID('fd586f63-8cd5-40f8-bf26-af1ab911e3dd'), permission_denied=False, name='inference-2024_04_16-08_26_12_590711')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the `with_options` method allows us to pass in pipeline settings\n",
    "#  and returns a configured pipeline\n",
    "inference_configured = inference.with_options(**pipeline_settings)\n",
    "\n",
    "# Let's run it again to make sure we have two versions\n",
    "# We need to pass in the ID of the preprocessing done in the feature engineering pipeline\n",
    "# in order to avoid training-serving skew\n",
    "preprocessing_pipeline_artifact_version = client.get_artifact_version(\"preprocess_pipeline\")\n",
    "\n",
    "inference_configured(\n",
    "    preprocess_pipeline_id=preprocessing_pipeline_artifact_version.id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2935d1fa",
   "metadata": {},
   "source": [
    "ZenML automatically links all artifacts to the `production` model version as well, including the predictions\n",
    "that were returned in the pipeline. This completes the MLOps loop of training to inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e191d019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1\n",
       "1     0\n",
       "2     0\n",
       "3     1\n",
       "4     1\n",
       "5     0\n",
       "6     0\n",
       "7     0\n",
       "8     0\n",
       "9     1\n",
       "10    1\n",
       "11    0\n",
       "12    1\n",
       "13    0\n",
       "14    1\n",
       "15    0\n",
       "16    1\n",
       "17    1\n",
       "18    1\n",
       "19    0\n",
       "20    0\n",
       "21    1\n",
       "22    0\n",
       "23    1\n",
       "24    1\n",
       "25    1\n",
       "26    1\n",
       "27    1\n",
       "Name: series, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch production model\n",
    "production_model_version = client.get_model_version(\"breast_cancer_classifier\", \"production\")\n",
    "\n",
    "# Get the predictions artifact\n",
    "production_model_version.get_artifact(\"predictions\").load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a73cdf",
   "metadata": {},
   "source": [
    "You can also see all predictions ever created as a complete history in the dashboard:\n",
    "\n",
    "<img src=\".assets/cloud_mcp_predictions.png\" width=\"70%\" alt=\"Model Control Plane\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594ee4fc-f102-4b99-bdc3-2f1670c87679",
   "metadata": {},
   "source": [
    "## Congratulations!\n",
    "\n",
    "You're a legit MLOps engineer now! You trained two models, evaluated them against\n",
    "a test set, registered the best one with the ZenML model control plane,\n",
    "and served some predictions. You also learned how to iterate on your models and\n",
    "data by using some of the ZenML utility abstractions. You saw how to view your\n",
    "artifacts and models via the client as well as the ZenML Dashboard.\n",
    "\n",
    "## Further exploration\n",
    "\n",
    "This was just the tip of the iceberg of what ZenML can do; check out the [**docs**](https://docs.zenml.io/) to learn more\n",
    "about the capabilities of ZenML. For example, you might want to:\n",
    "\n",
    "- [Deploy ZenML](https://docs.zenml.io/user-guide/production-guide/connect-deployed-zenml) to collaborate with your colleagues.\n",
    "- Run the same pipeline on a [cloud MLOps stack in production](https://docs.zenml.io/user-guide/production-guide/cloud-stack).\n",
    "- Track your metrics in an experiment tracker like [MLflow](https://docs.zenml.io/stacks-and-components/component-guide/experiment-trackers/mlflow).\n",
    "\n",
    "## What next?\n",
    "\n",
    "* If you have questions or feedback... join our [**Slack Community**](https://zenml.io/slack) and become part of the ZenML family!\n",
    "* If you want to quickly get started with ZenML, check out the [ZenML Cloud](https://zenml.io/cloud)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254feedb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
