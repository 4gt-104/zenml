{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/zenml-io/zenml/blob/main/examples/quickstart/quickstart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RO_v5iIaYFi2"
   },
   "source": [
    "# ZenML Quickstart Guide\n",
    "\n",
    "Our goal here is to help you to get the first practical experience with our tool and give you a brief overview on some basic functionalities of ZenML.\n",
    "\n",
    "The quickest way to get started is to create a simple pipeline. We'll be using the [MNIST](http://yann.lecun.com/exdb/mnist/) dataset (originally developed by Yann LeCun and others) digits, and then later the [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) dataset developed by Zalando.\n",
    "\n",
    "If you want to run this notebook in an interactive environment, feel free to run it in a Google Colab.\n",
    "\n",
    "## Purpose\n",
    "\n",
    "This quickstart guide is designed to provide a practical introduction to some of the main concepts and paradigms used by the ZenML framework. If you want more detail, our [full documentation](https://docs.zenml.io/) provides more on the concepts and how to implement them.\n",
    "\n",
    "## Using Google Colab\n",
    "\n",
    "You will want to use a GPU for this example. If you are following this quickstart in Google's Colab, follow these steps:\n",
    "\n",
    "- Before running anything, you need to tell Colab that you want to use a GPU. You can do this by clicking on the ‘Runtime’ tab and selecting ‘Change runtime type’. A pop-up window will open up with a drop-down menu.\n",
    "- Select ‘GPU’ from the menu and click ‘Save’.\n",
    "- It may ask if you want to restart the runtime. If so, go ahead and do that.\n",
    "\n",
    "<!-- The code for the MNIST training borrows heavily from [this](https://www.tensorflow.org/datasets/keras_example) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VNLEesHEyjkg"
   },
   "source": [
    "## Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x7l4qDgcI_5F",
    "outputId": "ed764976-0d95-4e5f-e75d-805d2bab804c"
   },
   "outputs": [],
   "source": [
    "# Install the ZenML CLI tool and Tensorflow\n",
    "!pip install zenml==\"0.5.0rc2\" tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_RCPyaNzPy-"
   },
   "source": [
    "Once the installation is completed, you can go ahead and create your first ZenML repository for your project. As ZenML repositories are built on top of Git repositories, you can create yours in a desired empty directory through:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-lcfE3l2zTU-",
    "outputId": "3d3e70af-c87a-4ac9-917d-b322823431e1"
   },
   "outputs": [],
   "source": [
    "# Initialize a git repository\n",
    "!git init\n",
    "\n",
    "# Initialize ZenML's .zen file\n",
    "!zenml init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQE8PSXDzL-_"
   },
   "source": [
    "Now, the setup is completed. For the next steps, just make sure that you are executing the code within your ZenML repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izjbDO-6yrFM"
   },
   "source": [
    "## Import relevant packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2gtj5QKCnSj0"
   },
   "source": [
    "We will use pipelines and steps in to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LvFo9epOUE7G",
    "outputId": "42bec4a0-41f9-4560-e9a1-e139f08c4e0a"
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from zenml.annotations import Input, Output, Step\n",
    "from zenml.artifacts import DataArtifact, ModelArtifact\n",
    "from zenml.pipelines import pipeline\n",
    "from zenml.steps import step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6UwqjAR2yvH_"
   },
   "source": [
    "## Define ZenML Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5wHcI2FinX2O"
   },
   "source": [
    "In the code that follows, you can see that we are defining the various steps of our pipeline. Each step is decorated with `@step`, the main abstraction that is currently available for creating pipeline steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZI9i2FJ0k3H"
   },
   "source": [
    "The first step is an `import` step that downloads the MNIST dataset and samples the first hundred rows for demo purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1VT_PAW10jbp",
    "outputId": "36ecdd08-3bca-42b4-d84d-be76126840e8"
   },
   "outputs": [],
   "source": [
    "@step(name=\"import_basic_mnist\")\n",
    "def ImportDataStep() -> List[float]:\n",
    "    \"\"\"Download the MNIST data store it as an artifact\"\"\"\n",
    "    (X_train, y_train), (\n",
    "        X_test,\n",
    "        y_test,\n",
    "    ) = tf.keras.datasets.mnist.load_data()\n",
    "    return [\n",
    "        X_train.tolist()[0:100],\n",
    "        y_train.tolist()[0:100],\n",
    "        X_test.tolist()[0:100],\n",
    "        y_test.tolist()[0:100],\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AU4OSa7Z0sc0"
   },
   "source": [
    "Secondly, we normalize all images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v_4bPrRB0rNy",
    "outputId": "06b150bd-e3ea-4940-c5be-f00f86331c7c"
   },
   "outputs": [],
   "source": [
    "@step(name=\"normalize\")\n",
    "def NormalizeDataStep(data: Input[DataArtifact]) -> List[float]:\n",
    "    \"\"\"Normalize the values for all the images so they are between 0 and 1\"\"\"\n",
    "    import_data = data.materializers.json.read_file()\n",
    "    X_train_normed = np.array(import_data[0]) / 255.0\n",
    "    X_test_normed = np.array(import_data[2]) / 255.0\n",
    "    return [\n",
    "        X_train_normed.tolist(),\n",
    "        import_data[1],\n",
    "        X_test_normed.tolist(),\n",
    "        import_data[3],\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ma53mucU0yF3"
   },
   "source": [
    "We then add a `Trainer` step, that takes the normalized data and trains a Keras classifier on the data. Note that the `Output[ModelArtifact]` type helps in writing the model out to our artifact store. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZEw7Cbqx0wXj",
    "outputId": "0603fa51-eb20-4c22-d499-9e7f1f3a972b"
   },
   "outputs": [],
   "source": [
    "@step(name=\"trainer\")\n",
    "def MNISTTrainModelStep(\n",
    "    data: Input[DataArtifact],\n",
    "    model_artifact: Output[ModelArtifact],\n",
    "    epochs: int,\n",
    "):\n",
    "    \"\"\"Train a neural net from scratch to recognise MNIST digits return our\n",
    "    model or the learner\"\"\"\n",
    "    import_data = data.materializers.json.read_file()\n",
    "\n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "            tf.keras.layers.Dense(10, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(10),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        import_data[0],\n",
    "        import_data[1],\n",
    "        epochs=epochs,\n",
    "    )\n",
    "\n",
    "    # write model\n",
    "    model_artifact.materializers.keras.write_model(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aU9ygH9s1BgR"
   },
   "source": [
    "Finally, we add an `Evaluator` step that takes as input the test set and the trained model and evaluates some final metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "37mMICD_URDW",
    "outputId": "873fe64b-1105-4181-8541-c31356069305"
   },
   "outputs": [],
   "source": [
    "@step(name=\"evaluate\")\n",
    "def EvaluateModelStep(\n",
    "    data: Input[DataArtifact], model_artifact: Input[ModelArtifact]\n",
    ") -> List[float]:\n",
    "    \"\"\"Calculate the loss for the model for each epoch in a graph\"\"\"\n",
    "    model = model_artifact.materializers.keras.read_model()\n",
    "    import_data = data.materializers.json.read_file()\n",
    "\n",
    "    test_loss, test_acc = model.evaluate(\n",
    "        import_data[2], import_data[3], verbose=2\n",
    "    )\n",
    "    return [test_loss, test_acc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_iZTIz8y7Cp"
   },
   "source": [
    "## Define ZenML Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oKbU3WlbnoiA"
   },
   "source": [
    "A pipeline is defined with the `@pipeline` decorator. This defines the various steps of the pipeline and specifies the dependencies between the steps, thereby determining the order in which they will be run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rm8SIrLFWenn"
   },
   "outputs": [],
   "source": [
    "# Define the pipeline\n",
    "\n",
    "@pipeline(\"mnist\")\n",
    "def MNISTTrainingPipeline(\n",
    "    import_data: Step[ImportDataStep],\n",
    "    normalize_data: Step[NormalizeDataStep],\n",
    "    trainer: Step[MNISTTrainModelStep],\n",
    "    evaluator: Step[EvaluateModelStep],\n",
    "):\n",
    "    # Link all the steps artifacts together\n",
    "    normalize_data(data=import_data.outputs.return_output)\n",
    "    trainer(data=normalize_data.outputs.return_output)\n",
    "    evaluator(\n",
    "        data=normalize_data.outputs.return_output,\n",
    "        model_artifact=trainer.outputs.model_artifact,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-JtDHu_z1IX"
   },
   "source": [
    "## Initialise a Pipeline Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NrJA5OSgnydC"
   },
   "source": [
    "Here we initialise a run of our `MNISTTrainingPipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dRzZA406UVVz",
    "outputId": "2d5e9967-87b7-4553-a104-b1b6602e10a6"
   },
   "outputs": [],
   "source": [
    "# Initialise the pipeline\n",
    "mnist_trainer = MNISTTrainingPipeline(\n",
    "    import_data=ImportDataStep(),\n",
    "    normalize_data=NormalizeDataStep(),\n",
    "    trainer=MNISTTrainModelStep(epochs=10),\n",
    "    evaluator=EvaluateModelStep(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zKpVG4RXz403"
   },
   "source": [
    "## Run the Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QzSHv8GioAkW"
   },
   "source": [
    "Running the pipeline is as simple as calling the `run()` method on the defined pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mLZf7mdmUW_M",
    "outputId": "539b9c10-a3b4-4ac3-8f44-edc1b2babe11"
   },
   "outputs": [],
   "source": [
    "# Run the pipeline\n",
    "mnist_trainer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gotkJdTQz8j2"
   },
   "source": [
    "## From MNIST to Fashion MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PMLU4cNW-Ei4"
   },
   "source": [
    "We got pretty good results on the MNIST model that we trained, but maybe we want to see how a similar training pipeline would work on a different dataset.\n",
    "\n",
    "You can see how easy it is to switch out one data import step and processing for another in our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rIfD-3-Ms8k1",
    "outputId": "8e3d0006-e788-48ff-dfba-9e0fa4b550c0"
   },
   "outputs": [],
   "source": [
    "# Define a new modified import data step to download the Fashion MNIST model\n",
    "@step(name=\"import_fashion_mnist\")\n",
    "def ImportDataStep() -> List[float]:\n",
    "    \"\"\"Download the Fashion MNIST data store it as an artifact\"\"\"\n",
    "    (X_train, y_train), (\n",
    "        X_test,\n",
    "        y_test,\n",
    "    ) = tf.keras.datasets.fashion_mnist.load_data()  # CHANGING to fashion\n",
    "    return [\n",
    "        X_train.tolist()[0:100],\n",
    "        y_train.tolist()[0:100],\n",
    "        X_test.tolist()[0:100],\n",
    "        y_test.tolist()[0:100],\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9oQO-ZGE4Kwf",
    "outputId": "c2fb7281-60ee-4126-b859-b8230a1d112b"
   },
   "outputs": [],
   "source": [
    "# Initialise a new pipeline\n",
    "fashion_mnist_trainer = MNISTTrainingPipeline(\n",
    "    import_data=ImportDataStep(),\n",
    "    normalize_data=NormalizeDataStep(),\n",
    "    trainer=MNISTTrainModelStep(epochs=10),\n",
    "    evaluator=EvaluateModelStep(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4t-KrsOfoKA4",
    "outputId": "5e78731d-df35-45d3-80ab-fe6ff1be2879"
   },
   "outputs": [],
   "source": [
    "# Run the new pipeline\n",
    "fashion_mnist_trainer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uOJtVVaFzlUO"
   },
   "source": [
    "… and that's it for the quickstart. If you came here without a hiccup, you must have successly installed ZenML, set up a ZenML repo, configured a training pipeline, executed it and evaluated the results. And, this is just the tip of the iceberg on the capabilities of ZenML.\n",
    "\n",
    "However, if you had a hiccup or you have some suggestions/questions regarding our framework, you can always check our [docs](https://docs.zenml.io/) or our [Github](https://github.com/zenml-io/zenml) or even better join us on our [Slack channel](https://zenml.io/slack-invite).\n",
    "\n",
    "Cheers!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "22gkBKSntlF8"
   },
   "source": [
    "For more detailed information on all the components and steps that went into this short example, please continue reading [our more detailed documentation pages](https://docs.zenml.io/)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "ZenML Quickstart.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
