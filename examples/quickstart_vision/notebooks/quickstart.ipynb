{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will finetune a pretrained MobileNetv2 model on the Fashion MNIST dataset using Pytorch.\n",
    "\n",
    "Following the [Pytorch Quickstart](https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html)\n",
    "\n",
    "However we change the train() and test() functions to log their losses and accuracies\n",
    "to TensorBoard instead of printing them, following the [Pytorch TensorBoard Tutorial](https://pytorch.org/docs/stable/tensorboard.html).\n",
    "\n",
    "This is the state of ML in research, following shows how to transition to prod with ZenML.\n",
    "\n",
    "Additionally, we also log all hyperparameters and final metrics to MLFlow.\n",
    "\n",
    "Furthermore, in addition to the data loading, training, and testing from the PyTorch quickstart,\n",
    "we also deploy the model with MLFlow and define an inference pipeline that sends\n",
    "inference requests to it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zenml integration install pytorch mlflow deepchecks dash -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "from zenml.steps import step, Output\n",
    "from zenml.pipelines import pipeline\n",
    "from zenml.integrations.mlflow.mlflow_step_decorator import enable_mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def load_data() -> Output(\n",
    "    train_dataloader=DataLoader, test_dataloader=DataLoader\n",
    "):\n",
    "    \"\"\"Load the Fashion MNIST dataset as tuple of torch Datasets.\n",
    "    \n",
    "    From https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html.\n",
    "    \"\"\"\n",
    "    batch_size = 64\n",
    "\n",
    "    # Download training data from open datasets.\n",
    "    training_data = datasets.FashionMNIST(\n",
    "        root=\"data\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=ToTensor(),\n",
    "    )\n",
    "\n",
    "    # Download test data from open datasets.\n",
    "    test_data = datasets.FashionMNIST(\n",
    "        root=\"data\",\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=ToTensor(),\n",
    "    )\n",
    "\n",
    "    # Create data loaders.\n",
    "    train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "    test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "    return train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "@step\n",
    "def load_model() -> nn.Module:\n",
    "    \"\"\"Define a PyTorch classification model.\n",
    "    \n",
    "    From https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html.\n",
    "    \"\"\"\n",
    "    model = NeuralNetwork()\n",
    "    print(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from zenml.steps import StepContext\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer, device, tensorboard_writer, global_step):\n",
    "    \"\"\"Train a model for one epoch.\n",
    "    \n",
    "    From https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html.\n",
    "    \"\"\"\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    correct, accuracy = 0, 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            step_in_epoch = (batch + 1) * len(X)\n",
    "            current_step = global_step + step_in_epoch\n",
    "            loss = loss.item()\n",
    "            accuracy = 100 * correct / step_in_epoch\n",
    "            tensorboard_writer.add_scalar(\"Loss/train\", loss, current_step)\n",
    "            tensorboard_writer.add_scalar(\"Accuracy/train\", accuracy, current_step)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def test(dataloader, model, loss_fn, device, tensorboard_writer, global_step):\n",
    "    \"\"\"Test a model on the validation / test dataset.\n",
    "    \n",
    "    From https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html.\n",
    "    \"\"\"\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    test_accuracy = 100 * correct / size\n",
    "    tensorboard_writer.add_scalar(\"Loss/test\", test_loss, global_step)\n",
    "    tensorboard_writer.add_scalar(\"Accuracy/test\", test_accuracy, global_step)\n",
    "    return test_accuracy\n",
    "\n",
    "@enable_mlflow  # setup MLflow\n",
    "@step(enable_cache=False)\n",
    "def train_test(\n",
    "    model: nn.Module,\n",
    "    train_dataloader: DataLoader, \n",
    "    test_dataloader: DataLoader, \n",
    "    context: StepContext,\n",
    ") -> Output(trained_model=nn.Module, test_acc=float):\n",
    "    \"\"\"Train and simultaneously evaluate a torch model on given dataloaders.\n",
    "    \n",
    "    Adjusted from https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html.\n",
    "    \"\"\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    log_dir = os.path.join(context.get_output_artifact_uri(output_name=\"trained_model\"), \"logs\")\n",
    "    tensorboard_writer = SummaryWriter(log_dir)\n",
    "    print(f\"Using {device} device\")\n",
    "    model = model.to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "    epochs = 5\n",
    "    test_acc = 0\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        global_step = t * len(train_dataloader)\n",
    "        train_acc = train(train_dataloader, model, loss_fn, optimizer, device, tensorboard_writer, global_step)\n",
    "        test_acc = test(test_dataloader, model, loss_fn, device, tensorboard_writer, global_step)\n",
    "    print(\"Done!\")\n",
    "    mlflow.log_metric(\"Train Accuracy\", train_acc)\n",
    "    mlflow.log_metric(\"Test Accuracy\", test_acc)\n",
    "    mlflow.pytorch.log_model(model, \"model\")\n",
    "    return model, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def deployment_trigger(test_acc: float) -> bool:\n",
    "    \"\"\"Only deploy if the test accuracy > 90%.\"\"\"\n",
    "    return test_acc > 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.integrations.mlflow.steps import mlflow_model_deployer_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.pipelines import pipeline\n",
    "\n",
    "\n",
    "@pipeline(enable_cache=False)\n",
    "def training_pipeline(\n",
    "    load_training_data,\n",
    "    model_definition,\n",
    "    train_test,\n",
    "    deployment_trigger,\n",
    "    model_deployer,\n",
    "):\n",
    "    \"\"\"Train, evaluate, and deploy a model.\"\"\"\n",
    "    train_dataloader, test_dataloader = load_training_data()\n",
    "    model = model_definition()\n",
    "    model, test_acc = train_test(model, train_dataloader, test_dataloader)\n",
    "    deployment_decision = deployment_trigger(test_acc)\n",
    "    model_deployer(deployment_decision, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_pipeline(\n",
    "    load_training_data=load_data(),\n",
    "    model_definition=load_model(),\n",
    "    train_test=train_test(),\n",
    "    deployment_trigger=deployment_trigger(),\n",
    "    model_deployer=mlflow_model_deployer_step(),\n",
    ").run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zenml model-deployer models list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorBoard Experiment Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.integrations.tensorboard.visualizers import (\n",
    "    stop_tensorboard_server,\n",
    "    visualize_tensorboard,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_tensorboard(\n",
    "    pipeline_name=\"training_pipeline\",\n",
    "    step_name=\"train_test\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLflow Experiment Tracking\n",
    "\n",
    "Lastly, remember how we added MLflow experiment tracking to our `svc_trainer_mlflow` step before?\n",
    "Those two simple lines of code automatically configured and initialized MLflow and logged all hyperparameters and metrics there.\n",
    "\n",
    "Let's start up the MLflow UI and check it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.environment import Environment\n",
    "from zenml.integrations.mlflow.mlflow_utils import get_tracking_uri\n",
    "\n",
    "\n",
    "def open_mlflow_ui(port=4997):\n",
    "    if Environment.in_google_colab():\n",
    "        from pyngrok import ngrok\n",
    "\n",
    "        public_url = ngrok.connect(port)\n",
    "        print(f\"\\x1b[31mIn Colab, use this URL instead: {public_url}!\\x1b[0m\")\n",
    "\n",
    "    !mlflow ui --backend-store-uri=\"{get_tracking_uri()}\" --port={port}\n",
    "\n",
    "\n",
    "open_mlflow_ui()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline(enable_cache=False)\n",
    "def inference_pipeline(\n",
    "    inference_data_loader,\n",
    "    prediction_service_loader,\n",
    "    predictor,\n",
    "):\n",
    "    \"\"\"Inference pipeline with data drift detection.\"\"\"\n",
    "    inference_data = inference_data_loader()\n",
    "    model_deployment_service = prediction_service_loader()\n",
    "    predictor(model_deployment_service, inference_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "@step\n",
    "def inference_data_loader() -> np.ndarray:\n",
    "    \"\"\"Load some (random) inference data.\"\"\"\n",
    "    return np.random.rand(10, 1, 24, 24)  # 10 images, each 24x24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.services import BaseService\n",
    "from zenml.repository import Repository\n",
    "\n",
    "\n",
    "@step(enable_cache=False)\n",
    "def prediction_service_loader() -> BaseService:\n",
    "    \"\"\"Load the model service of our train_evaluate_deploy_pipeline.\"\"\"\n",
    "    repo = Repository()\n",
    "    model_deployer = repo.active_stack.model_deployer\n",
    "    services = model_deployer.find_model_server(\n",
    "        pipeline_name=\"training_pipeline\",\n",
    "        pipeline_step_name=\"mlflow_model_deployer_step\",\n",
    "        running=True,\n",
    "    )\n",
    "    service = services[0]\n",
    "    return service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def predictor(\n",
    "    service: BaseService,\n",
    "    data: np.ndarray,\n",
    ") -> Output(predictions=list):\n",
    "    \"\"\"Run a inference request against a prediction service\"\"\"\n",
    "    service.start(timeout=10)  # should be a NOP if already started\n",
    "    prediction = service.predict(data)\n",
    "    prediction = prediction.argmax(axis=-1)\n",
    "    print(f\"Prediction is: {[prediction.tolist()]}\")\n",
    "    return [prediction.tolist()]\n",
    "\n",
    "\n",
    "# @step\n",
    "# def predict(model: nn.Module, test_data: Dataset):\n",
    "\n",
    "#     classes = [\n",
    "#         \"T-shirt/top\",\n",
    "#         \"Trouser\",\n",
    "#         \"Pullover\",\n",
    "#         \"Dress\",\n",
    "#         \"Coat\",\n",
    "#         \"Sandal\",\n",
    "#         \"Shirt\",\n",
    "#         \"Sneaker\",\n",
    "#         \"Bag\",\n",
    "#         \"Ankle boot\",\n",
    "#     ]\n",
    "\n",
    "#     model.eval()\n",
    "#     x, y = test_data[0][0], test_data[0][1]\n",
    "#     with torch.no_grad():\n",
    "#         pred = model(x)\n",
    "#         predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "#         print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_pipeline(\n",
    "    inference_data_loader=inference_data_loader(),\n",
    "    prediction_service_loader=prediction_service_loader(),\n",
    "    predictor=predictor(),\n",
    ").run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit ('zenml-vision-quickstart')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d4dcc2e3e627cec923777cdd7927d8fa67a4e42e9d8d88a862cabfd58cc1dc5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
