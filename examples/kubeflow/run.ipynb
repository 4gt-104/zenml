{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zenml-io/zenml/blob/main/examples/kubeflow/run.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO_v5iIaYFi2"
      },
      "source": [
        "# ZenML Quickstart Guide\n",
        "\n",
        "Our goal here is to help you to get the first practical experience with our tool and give you a brief overview on some basic functionalities of ZenML. We'll create a training pipeline for the [MNIST](http://yann.lecun.com/exdb/mnist/) dataset and then later the [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) dataset developed by Zalando.\n",
        "\n",
        "If you want to run this notebook in an interactive environment, feel free to run it in a [Google Colab](https://colab.research.google.com/github/zenml-io/zenml/blob/main/examples/quickstart/quickstart.ipynb) or view it on [GitHub](https://github.com/zenml-io/zenml/tree/main/examples/quickstart) directly.\n",
        "\n",
        "\n",
        "## Purpose\n",
        "\n",
        "This quickstart guide is designed to provide a practical introduction to some of the main concepts and paradigms used by the ZenML framework. If you want more detail, our [full documentation](https://docs.zenml.io/) provides more on the concepts and how to implement them.\n",
        "\n",
        "## Using Google Colab\n",
        "\n",
        "You will want to use a GPU for this example. If you are following this quickstart in Google's Colab, follow these steps:\n",
        "\n",
        "- Before running anything, you need to tell Colab that you want to use a GPU. You can do this by clicking on the ‘Runtime’ tab and selecting ‘Change runtime type’. A pop-up window will open up with a drop-down menu.\n",
        "- Select ‘GPU’ from the menu and click ‘Save’.\n",
        "- It may ask if you want to restart the runtime. If so, go ahead and do that.\n",
        "\n",
        "<!-- The code for the MNIST training borrows heavily from [this](https://www.tensorflow.org/datasets/keras_example) -->\n",
        "\n",
        "## Relation to quickstart.py\n",
        "This notebook is a variant of [quickstart.py](https://github.com/zenml-io/zenml/blob/main/examples/quickstart/quickstart.py) which is shown off in the [ZenML Docs](https://docs.zenml.io). The core difference being it adds a modular aspect of the importer step and shows how to fetch pipelines, runs, and artifacts in the post-execution workflow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNLEesHEyjkg"
      },
      "source": [
        "## Install libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7l4qDgcI_5F",
        "outputId": "b413e26c-e610-4803-e39b-55906cb1f31b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting zenml\n",
            "  Downloading zenml-0.5.5-py3-none-any.whl (264 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▎                              | 10 kB 18.8 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 20 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 30 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |█████                           | 40 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 51 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 61 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 71 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 81 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 92 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 102 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 112 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 122 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 133 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 143 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 153 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 163 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 174 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 184 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 194 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 204 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 215 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 225 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 235 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 245 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 256 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 264 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas<2.0.0,>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from zenml) (1.1.5)\n",
            "Collecting apache-beam<3.0.0,>=2.30.0\n",
            "  Downloading apache_beam-2.34.0-cp37-cp37m-manylinux2010_x86_64.whl (9.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.8 MB 39.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.8.1 in /usr/local/lib/python3.7/dist-packages (from zenml) (2.8.2)\n",
            "Requirement already satisfied: tabulate<0.9.0,>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from zenml) (0.8.9)\n",
            "Collecting distro<2.0.0,>=1.6.0\n",
            "  Downloading distro-1.6.0-py2.py3-none-any.whl (19 kB)\n",
            "Collecting click<9.0.0,>=8.0.1\n",
            "  Downloading click-8.0.3-py3-none-any.whl (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 5.5 MB/s \n",
            "\u001b[?25hCollecting ml-pipelines-sdk<2.0.0,>=1.3.0\n",
            "  Downloading ml_pipelines_sdk-1.4.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 56.0 MB/s \n",
            "\u001b[?25hCollecting pydantic<2.0.0,>=1.8.2\n",
            "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 18.0 MB/s \n",
            "\u001b[?25hCollecting pyyaml<6.0.0,>=5.4.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 56.5 MB/s \n",
            "\u001b[?25hCollecting analytics-python<2.0.0,>=1.4.0\n",
            "  Downloading analytics_python-1.4.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting gitpython<4.0.0,>=3.1.18\n",
            "  Downloading GitPython-3.1.24-py3-none-any.whl (180 kB)\n",
            "\u001b[K     |████████████████████████████████| 180 kB 73.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from analytics-python<2.0.0,>=1.4.0->zenml) (1.15.0)\n",
            "Collecting monotonic>=1.5\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: requests<3.0,>=2.7 in /usr/local/lib/python3.7/dist-packages (from analytics-python<2.0.0,>=1.4.0->zenml) (2.23.0)\n",
            "Collecting backoff==1.10.0\n",
            "  Downloading backoff-1.10.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting dill<0.3.2,>=0.3.1.1\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[K     |████████████████████████████████| 151 kB 70.5 MB/s \n",
            "\u001b[?25hCollecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading hdfs-2.6.0-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: protobuf<4,>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from apache-beam<3.0.0,>=2.30.0->zenml) (3.17.3)\n",
            "Requirement already satisfied: numpy<1.21.0,>=1.14.3 in /usr/local/lib/python3.7/dist-packages (from apache-beam<3.0.0,>=2.30.0->zenml) (1.19.5)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam<3.0.0,>=2.30.0->zenml) (1.3.0)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam<3.0.0,>=2.30.0->zenml) (1.7)\n",
            "Collecting requests<3.0,>=2.7\n",
            "  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 835 kB/s \n",
            "\u001b[?25hCollecting future<1.0.0,>=0.18.2\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 56.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam<3.0.0,>=2.30.0->zenml) (3.12.1)\n",
            "Requirement already satisfied: grpcio<2,>=1.29.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam<3.0.0,>=2.30.0->zenml) (1.42.0)\n",
            "Requirement already satisfied: typing-extensions<4,>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam<3.0.0,>=2.30.0->zenml) (3.10.0.2)\n",
            "Collecting avro-python3!=1.9.2,<1.10.0,>=1.8.1\n",
            "  Downloading avro-python3-1.9.2.1.tar.gz (37 kB)\n",
            "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.7/dist-packages (from apache-beam<3.0.0,>=2.30.0->zenml) (2018.9)\n",
            "Requirement already satisfied: oauth2client<5,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam<3.0.0,>=2.30.0->zenml) (4.1.3)\n",
            "Collecting orjson<4.0\n",
            "  Downloading orjson-3.6.5-cp37-cp37m-manylinux_2_24_x86_64.whl (247 kB)\n",
            "\u001b[K     |████████████████████████████████| 247 kB 45.0 MB/s \n",
            "\u001b[?25hCollecting fastavro<2,>=0.21.4\n",
            "  Downloading fastavro-1.4.7-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 60.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow<6.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam<3.0.0,>=2.30.0->zenml) (3.0.0)\n",
            "Requirement already satisfied: httplib2<0.20.0,>=0.8 in /usr/local/lib/python3.7/dist-packages (from apache-beam<3.0.0,>=2.30.0->zenml) (0.17.4)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from click<9.0.0,>=8.0.1->zenml) (4.8.2)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.3 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam<3.0.0,>=2.30.0->zenml) (0.6.2)\n",
            "Collecting ml-metadata<1.5.0,>=1.4.0\n",
            "  Downloading ml_metadata-1.4.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 44.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py<0.13,>=0.9 in /usr/local/lib/python3.7/dist-packages (from ml-pipelines-sdk<2.0.0,>=1.3.0->zenml) (0.12.0)\n",
            "Collecting google-apitools<1,>=0.5\n",
            "  Downloading google_apitools-0.5.32-py3-none-any.whl (135 kB)\n",
            "\u001b[K     |████████████████████████████████| 135 kB 71.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-api-python-client<2,>=1.8 in /usr/local/lib/python3.7/dist-packages (from ml-pipelines-sdk<2.0.0,>=1.3.0->zenml) (1.12.8)\n",
            "Requirement already satisfied: jinja2<4,>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from ml-pipelines-sdk<2.0.0,>=1.3.0->zenml) (2.11.3)\n",
            "Collecting packaging<21,>=20\n",
            "  Downloading packaging-20.9-py2.py3-none-any.whl (40 kB)\n",
            "\u001b[K     |████████████████████████████████| 40 kB 4.6 MB/s \n",
            "\u001b[?25hCollecting docker<5,>=4.1\n",
            "  Downloading docker-4.4.4-py2.py3-none-any.whl (147 kB)\n",
            "\u001b[K     |████████████████████████████████| 147 kB 57.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: portpicker<2,>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from ml-pipelines-sdk<2.0.0,>=1.3.0->zenml) (1.3.9)\n",
            "Collecting websocket-client>=0.32.0\n",
            "  Downloading websocket_client-1.2.3-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client<2,>=1.8->ml-pipelines-sdk<2.0.0,>=1.3.0->zenml) (1.35.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client<2,>=1.8->ml-pipelines-sdk<2.0.0,>=1.3.0->zenml) (0.0.4)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client<2,>=1.8->ml-pipelines-sdk<2.0.0,>=1.3.0->zenml) (1.26.3)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client<2,>=1.8->ml-pipelines-sdk<2.0.0,>=1.3.0->zenml) (3.0.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client<2,>=1.8->ml-pipelines-sdk<2.0.0,>=1.3.0->zenml) (1.53.0)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client<2,>=1.8->ml-pipelines-sdk<2.0.0,>=1.3.0->zenml) (57.4.0)\n",
            "Collecting fasteners>=0.14\n",
            "  Downloading fasteners-0.16.3-py2.py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client<2,>=1.8->ml-pipelines-sdk<2.0.0,>=1.3.0->zenml) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client<2,>=1.8->ml-pipelines-sdk<2.0.0,>=1.3.0->zenml) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client<2,>=1.8->ml-pipelines-sdk<2.0.0,>=1.3.0->zenml) (4.2.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2<4,>=2.7.3->ml-pipelines-sdk<2.0.0,>=1.3.0->zenml) (2.0.1)\n",
            "Collecting attrs<21,>=20.3\n",
            "  Downloading attrs-20.3.0-py2.py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 5.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client<5,>=2.0.1->apache-beam<3.0.0,>=2.30.0->zenml) (0.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging<21,>=20->ml-pipelines-sdk<2.0.0,>=1.3.0->zenml) (3.0.6)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.7->analytics-python<2.0.0,>=1.4.0->zenml) (2.10)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.7->analytics-python<2.0.0,>=1.4.0->zenml) (2.0.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.7->analytics-python<2.0.0,>=1.4.0->zenml) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.7->analytics-python<2.0.0,>=1.4.0->zenml) (2021.10.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->click<9.0.0,>=8.0.1->zenml) (3.6.0)\n",
            "Building wheels for collected packages: avro-python3, dill, future\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.9.2.1-py3-none-any.whl size=43512 sha256=456d710349e91c80a6325fd7322f876f4d13cd5b898fb578a9745206f756876a\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/49/5f/fdb5b9d85055c478213e0158ac122b596816149a02d82e0ab1\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78546 sha256=5cf36c755fe6699ee83288826c53a2d442b204f9bd931c3654dc87c021e8f16c\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=e394481d7121b1732402bb755e0722b5f40b9c1c2dfa723d148abbab76227df5\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "Successfully built avro-python3 dill future\n",
            "Installing collected packages: requests, packaging, websocket-client, smmap, fasteners, attrs, orjson, monotonic, ml-metadata, hdfs, google-apitools, gitdb, future, fastavro, docker, dill, backoff, avro-python3, pyyaml, pydantic, ml-pipelines-sdk, gitpython, distro, click, apache-beam, analytics-python, zenml\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 21.3\n",
            "    Uninstalling packaging-21.3:\n",
            "      Successfully uninstalled packaging-21.3\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 21.2.0\n",
            "    Uninstalling attrs-21.2.0:\n",
            "      Successfully uninstalled attrs-21.2.0\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.4\n",
            "    Uninstalling dill-0.3.4:\n",
            "      Successfully uninstalled dill-0.3.4\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 7.1.2\n",
            "    Uninstalling click-7.1.2:\n",
            "      Successfully uninstalled click-7.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "multiprocess 0.70.12.2 requires dill>=0.3.4, but you have dill 0.3.1.1 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n",
            "flask 1.1.4 requires click<8.0,>=5.1, but you have click 8.0.3 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed analytics-python-1.4.0 apache-beam-2.34.0 attrs-20.3.0 avro-python3-1.9.2.1 backoff-1.10.0 click-8.0.3 dill-0.3.1.1 distro-1.6.0 docker-4.4.4 fastavro-1.4.7 fasteners-0.16.3 future-0.18.2 gitdb-4.0.9 gitpython-3.1.24 google-apitools-0.5.32 hdfs-2.6.0 ml-metadata-1.4.0 ml-pipelines-sdk-1.4.0 monotonic-1.6 orjson-3.6.5 packaging-20.9 pydantic-1.8.2 pyyaml-5.4.1 requests-2.26.0 smmap-5.0.0 websocket-client-1.2.3 zenml-0.5.5\n"
          ]
        }
      ],
      "source": [
        "# Install the ZenML CLI tool and Tensorflow\n",
        "!pip install zenml"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ['ZENML_DEBUG'] = 'true'\n",
        "os.environ['ZENML_LOGGING_VERBOSITY'] = 'INFO'\n",
        "os.environ['ZENML_ANALYTICS_OPT_IN'] = 'false'"
      ],
      "metadata": {
        "id": "VVaeGbDoIbXN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zenml integration get-requirements tensorflow"
      ],
      "metadata": {
        "id": "_c1rwma3IlvD",
        "outputId": "b7dd882e-9d0e-4aee-d671-d17eafc2a23a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m\u001b[1m\u001b[4mREQUIREMENTS FOR TENSORFLOW:\n",
            "\u001b[0m\n",
            "\u001b[32m['tensorflow']\u001b[0m\n",
            "\u001b[33m\u001b[1m\n",
            "To install the dependencies of a specific integration, type: \u001b[0m\n",
            "\u001b[33m\u001b[1mzenml integration install EXAMPLE_NAME\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_RCPyaNzPy-"
      },
      "source": [
        "Once the installation is completed, you can go ahead and create your first ZenML repository for your project. As ZenML repositories are built on top of Git repositories, you can create yours in a desired empty directory through:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lcfE3l2zTU-",
        "outputId": "fea5770a-d7de-4169-893c-eae2aa97f517"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized empty Git repository in /content/.git/\n",
            "\u001b[32mInitializing at /content\u001b[0m\n",
            "\u001b[32mZenML repo initialized at /content\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Initialize a git repository\n",
        "!git init\n",
        "\n",
        "# Initialize ZenML's .zen file\n",
        "!zenml init"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQE8PSXDzL-_"
      },
      "source": [
        "Now, the setup is completed. For the next steps, just make sure that you are executing the code within your ZenML repository."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izjbDO-6yrFM"
      },
      "source": [
        "## Import relevant packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gtj5QKCnSj0"
      },
      "source": [
        "We will use pipelines and steps in to train our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LvFo9epOUE7G"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from zenml.pipelines import pipeline\n",
        "from zenml.steps import step\n",
        "from zenml.steps.base_step_config import BaseStepConfig\n",
        "from zenml.steps.step_output import Output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UwqjAR2yvH_"
      },
      "source": [
        "## Define ZenML Steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wHcI2FinX2O"
      },
      "source": [
        "In the code that follows, you can see that we are defining the various steps of our pipeline. Each step is decorated with `@step`, the main abstraction that is currently available for creating pipeline steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZI9i2FJ0k3H"
      },
      "source": [
        "The first step is an `import` step that downloads the MNIST dataset and samples the first hundred rows for demo purposes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "1VT_PAW10jbp"
      },
      "outputs": [],
      "source": [
        "@step\n",
        "def importer() -> Output(\n",
        "    X_train=np.ndarray, y_train=np.ndarray, X_test=np.ndarray, y_test=np.ndarray\n",
        "):\n",
        "    \"\"\"Download the MNIST data store it as numpy arrays.\"\"\"\n",
        "    (X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "    return X_train, y_train, X_test, y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ma53mucU0yF3"
      },
      "source": [
        "We then add a `Trainer` step, that takes the normalized data and trains a Keras classifier on the data. Note that the `Output[ModelArtifact]` type helps in writing the model out to our artifact store. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ZEw7Cbqx0wXj"
      },
      "outputs": [],
      "source": [
        "class TrainerConfig(BaseStepConfig):\n",
        "    \"\"\"Trainer params\"\"\"\n",
        "\n",
        "    epochs: int = 1\n",
        "        \n",
        "@step\n",
        "def trainer(\n",
        "    X_train: np.ndarray,\n",
        "    y_train: np.ndarray,\n",
        "    config: TrainerConfig,\n",
        ") -> tf.keras.Model:\n",
        "    \"\"\"A simple Keras Model to train on the data.\"\"\"\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
        "    model.add(tf.keras.layers.Dense(10))\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "\n",
        "    model.fit(X_train, y_train, epochs=config.epochs)\n",
        "\n",
        "    # write model\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aU9ygH9s1BgR"
      },
      "source": [
        "Finally, we add an `Evaluator` step that takes as input the test set and the trained model and evaluates some final metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "37mMICD_URDW"
      },
      "outputs": [],
      "source": [
        "@step\n",
        "def evaluator(\n",
        "    X_test: np.ndarray,\n",
        "    y_test: np.ndarray,\n",
        "    model: tf.keras.Model,\n",
        ") -> float:\n",
        "    \"\"\"Calculate the accuracy on the test set\"\"\"\n",
        "    test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
        "    return test_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_iZTIz8y7Cp"
      },
      "source": [
        "## Define ZenML Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKbU3WlbnoiA"
      },
      "source": [
        "A pipeline is defined with the `@pipeline` decorator. This defines the various steps of the pipeline and specifies the dependencies between the steps, thereby determining the order in which they will be run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "rm8SIrLFWenn"
      },
      "outputs": [],
      "source": [
        "@pipeline\n",
        "def mnist_pipeline(\n",
        "    importer,\n",
        "    trainer,\n",
        "    evaluator,\n",
        "):\n",
        "    \"\"\"Links all the steps together in a pipeline\"\"\"\n",
        "    X_train, y_train, X_test, y_test = importer()\n",
        "    model = trainer(X_train=X_train, y_train=y_train)\n",
        "    evaluator(X_test=X_test, y_test=y_test, model=model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-JtDHu_z1IX"
      },
      "source": [
        "## Run the pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrJA5OSgnydC"
      },
      "source": [
        "Running the pipeline is as simple as calling the `run()` method on an instance of the defined pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRzZA406UVVz",
        "outputId": "f61e4408-4001-4cc7-ed7d-8472b1c4089f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;35mCreating pipeline: mnist_pipeline\u001b[0m\n",
            "\u001b[1;35mCache enabled for pipeline `\u001b[0m\u001b[33;21mmnist_pipeline`\u001b[1;35m\u001b[0m\n",
            "\u001b[1;35mUsing orchestrator `\u001b[0m\u001b[33;21mlocal_orchestrator`\u001b[1;35m for pipeline `\u001b[0m\u001b[33;21mmnist_pipeline`\u001b[1;35m. Running pipeline..\u001b[0m\n",
            "\u001b[1;35mStep `\u001b[0m\u001b[33;21mimporter`\u001b[1;35m has started.\u001b[0m\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "\u001b[1;35mStep `\u001b[0m\u001b[33;21mimporter`\u001b[1;35m has finished in 1.905s.\u001b[0m\n",
            "\u001b[1;35mStep `\u001b[0m\u001b[33;21mtrainer`\u001b[1;35m has started.\u001b[0m\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 9.5492 - accuracy: 0.8400\n",
            "INFO:tensorflow:Assets written to: /content/.zen/local_store/trainer/output/2/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/.zen/local_store/trainer/output/2/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;35mStep `\u001b[0m\u001b[33;21mtrainer`\u001b[1;35m has finished in 5.951s.\u001b[0m\n",
            "\u001b[1;35mStep `\u001b[0m\u001b[33;21mevaluator`\u001b[1;35m has started.\u001b[0m\n",
            "313/313 - 1s - loss: 6.3139 - accuracy: 0.8769 - 508ms/epoch - 2ms/step\n",
            "\u001b[1;35mStep `\u001b[0m\u001b[33;21mevaluator`\u001b[1;35m has finished in 0.960s.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Initialise the pipeline\n",
        "first_pipeline = mnist_pipeline(\n",
        "    importer=importer(),\n",
        "    trainer=trainer(config=TrainerConfig(epochs=1)),\n",
        "    evaluator=evaluator(),\n",
        ")\n",
        "first_pipeline.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gotkJdTQz8j2"
      },
      "source": [
        "## From MNIST to Fashion MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMLU4cNW-Ei4"
      },
      "source": [
        "We got pretty good results on the MNIST model that we trained, but maybe we want to see how a similar training pipeline would work on a different dataset.\n",
        "\n",
        "You can see how easy it is to switch out one data import step and processing for another in our pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "rIfD-3-Ms8k1"
      },
      "outputs": [],
      "source": [
        "# Define a new modified import data step to download the Fashion MNIST model\n",
        "@step\n",
        "def importer_fashion_mnist() -> Output(\n",
        "    X_train=np.ndarray, y_train=np.ndarray, X_test=np.ndarray, y_test=np.ndarray\n",
        "):\n",
        "    \"\"\"Download the MNIST data store it as an artifact\"\"\"\n",
        "    (X_train, y_train), (\n",
        "        X_test,\n",
        "        y_test,\n",
        "    ) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "    return X_train, y_train, X_test, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oQO-ZGE4Kwf",
        "outputId": "89bd665d-7dae-4cac-eda1-92e9f8bfda1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;35mCreating pipeline: mnist_pipeline\u001b[0m\n",
            "\u001b[1;35mCache enabled for pipeline `\u001b[0m\u001b[33;21mmnist_pipeline`\u001b[1;35m\u001b[0m\n",
            "\u001b[1;35mUsing orchestrator `\u001b[0m\u001b[33;21mlocal_orchestrator`\u001b[1;35m for pipeline `\u001b[0m\u001b[33;21mmnist_pipeline`\u001b[1;35m. Running pipeline..\u001b[0m\n",
            "\u001b[1;35mStep `\u001b[0m\u001b[33;21mimporter_fashion_mnist`\u001b[1;35m has started.\u001b[0m\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n",
            "\u001b[1;35mStep `\u001b[0m\u001b[33;21mimporter_fashion_mnist`\u001b[1;35m has finished in 2.318s.\u001b[0m\n",
            "\u001b[1;35mStep `\u001b[0m\u001b[33;21mtrainer`\u001b[1;35m has started.\u001b[0m\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 16.3738 - accuracy: 0.7480\n",
            "INFO:tensorflow:Assets written to: /content/.zen/local_store/trainer/output/5/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/.zen/local_store/trainer/output/5/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;35mStep `\u001b[0m\u001b[33;21mtrainer`\u001b[1;35m has finished in 4.942s.\u001b[0m\n",
            "\u001b[1;35mStep `\u001b[0m\u001b[33;21mevaluator`\u001b[1;35m has started.\u001b[0m\n",
            "313/313 - 0s - loss: 11.7584 - accuracy: 0.7952 - 453ms/epoch - 1ms/step\n",
            "\u001b[1;35mStep `\u001b[0m\u001b[33;21mevaluator`\u001b[1;35m has finished in 1.128s.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Initialise a new pipeline\n",
        "second_pipeline = mnist_pipeline(\n",
        "    importer=importer_fashion_mnist(),\n",
        "    trainer=trainer(config=TrainerConfig(epochs=1)),\n",
        "    evaluator=evaluator(),\n",
        ")\n",
        "\n",
        "# Run the new pipeline\n",
        "second_pipeline.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uKNmljpIYRh"
      },
      "source": [
        "# Post execution workflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "R5yPNQ1fIYRh"
      },
      "outputs": [],
      "source": [
        "from zenml.core.repo import Repository"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhG-rEDZIYRi"
      },
      "source": [
        "## Get repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "_cZqhydiIYRj"
      },
      "outputs": [],
      "source": [
        "repo = Repository()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-rao3-oIYRj"
      },
      "source": [
        "## Pipelines "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ZxMk-vsmIYRk"
      },
      "outputs": [],
      "source": [
        "pipelines = repo.get_pipelines()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFd--JgZIYRk"
      },
      "source": [
        "## Retrieve the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "2BSbKed-IYRk"
      },
      "outputs": [],
      "source": [
        "mnist_pipeline = pipelines[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpNKuyChIYRl"
      },
      "source": [
        "## Get the first run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "jI57bWbHIYRl"
      },
      "outputs": [],
      "source": [
        "runs = mnist_pipeline.runs  # chronologically ordered\n",
        "mnist_run = runs[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIPmpQCrIYRl"
      },
      "source": [
        "## Get the second run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "1SGaTPduIYRl"
      },
      "outputs": [],
      "source": [
        "fashion_mnist_run = runs[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDR1JNHtIYRm"
      },
      "source": [
        "## Get the steps (note the first step name is different)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Vct_wqq1IYRm",
        "outputId": "7800431d-813b-4721-f61d-27f4012f9d2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[StepView(id=1, name='importer', parameters={}),\n",
              " StepView(id=2, name='trainer', parameters={'epochs': 1}),\n",
              " StepView(id=3, name='evaluator', parameters={})]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "mnist_run.steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "lnQkTAv6IYRm",
        "outputId": "8fedfaf1-b5c9-4218-809c-244b8f6ebc2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[StepView(id=4, name='importer', parameters={}),\n",
              " StepView(id=5, name='trainer', parameters={'epochs': 1}),\n",
              " StepView(id=6, name='evaluator', parameters={})]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "fashion_mnist_run.steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5m6d6VPDIYRn"
      },
      "source": [
        "## Check the results of the evaluator and compare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "sF7YM4_iIYRn"
      },
      "outputs": [],
      "source": [
        "mnist_eval_step = mnist_run.get_step(name='evaluator')\n",
        "fashion_mnist_eval_step = fashion_mnist_run.get_step(name='evaluator')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "scrolled": true,
        "id": "V5fvkLoZIYRn",
        "outputId": "a8d0ad4d-bbd0-4320-a282-870120ac3ddf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[6.313859462738037, 0.8769000172615051]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# One output is simply called `output`, multiple is a dict called `outputs`.\n",
        "mnist_eval_step.output.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "wMBKfBSeIYRo",
        "outputId": "4387f938-bb21-492e-9c90-79a8b4329101",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[11.758384704589844, 0.795199990272522]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "fashion_mnist_eval_step.output.read()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Tan15BgIYRo"
      },
      "source": [
        "# Congratulations!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOJtVVaFzlUO"
      },
      "source": [
        "… and that's it for the quickstart. If you came here without a hiccup, you must have successly installed ZenML, set up a ZenML repo, configured a training pipeline, executed it and evaluated the results. And, this is just the tip of the iceberg on the capabilities of ZenML.\n",
        "\n",
        "However, if you had a hiccup or you have some suggestions/questions regarding our framework, you can always check our [docs](https://docs.zenml.io/) or our [Github](https://github.com/zenml-io/zenml) or even better join us on our [Slack channel](https://zenml.io/slack-invite).\n",
        "\n",
        "Cheers!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22gkBKSntlF8"
      },
      "source": [
        "For more detailed information on all the components and steps that went into this short example, please continue reading [our more detailed documentation pages](https://docs.zenml.io/)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ZenML Quickstart.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}