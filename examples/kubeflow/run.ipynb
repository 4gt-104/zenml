{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/zenml-io/zenml/blob/main/examples/kubeflow/run.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RO_v5iIaYFi2"
   },
   "source": [
    "# ZenML: Create production-ready ML pipelines\n",
    "\n",
    "Our goal here is to help you to get the first practical experience with our tool and give you a brief overview on some basic functionalities of ZenML. We'll create a training pipeline for the [MNIST](http://yann.lecun.com/exdb/mnist/) dataset. We will start local in the jupyter notebook but will transition over to a more robust environment with Kubeflow pipelines.\n",
    "\n",
    "If you want to run this notebook in an interactive environment, feel free to run it in a [Google Colab](https://colab.research.google.com/github/zenml-io/zenml/blob/main/examples/kubeflow/run.ipynb) or view it on [GitHub](https://github.com/zenml-io/zenml/tree/main/examples/kubeflow) directly.\n",
    "\n",
    "\n",
    "## Purpose\n",
    "\n",
    "This quickstart guide is designed to provide a practical introduction to some of the main concepts and paradigms used by the ZenML framework. If you want more detail, our [full documentation](https://docs.zenml.io/) provides more on the concepts and how to implement them.\n",
    "\n",
    "## Using Google Colab\n",
    "\n",
    "You will want to use a GPU for this example. If you are following this quickstart in Google's Colab, follow these steps:\n",
    "\n",
    "- Before running anything, you need to tell Colab that you want to use a GPU. You can do this by clicking on the ‘Runtime’ tab and selecting ‘Change runtime type’. A pop-up window will open up with a drop-down menu.\n",
    "- Select ‘GPU’ from the menu and click ‘Save’.\n",
    "- It may ask if you want to restart the runtime. If so, go ahead and do that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start developing locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VNLEesHEyjkg"
   },
   "source": [
    "## Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x7l4qDgcI_5F",
    "outputId": "b413e26c-e610-4803-e39b-55906cb1f31b"
   },
   "outputs": [],
   "source": [
    "# Install the ZenML CLI tool and Tensorflow\n",
    "!pip install zenml\n",
    "!zenml integration install kubeflow -f\n",
    "!zenml integration install sklearn -f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_RCPyaNzPy-"
   },
   "source": [
    "Once the installation is completed, you can go ahead and create your first ZenML repository for your project. As ZenML repositories are built on top of Git repositories, you can create yours in a desired empty directory through:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-lcfE3l2zTU-",
    "outputId": "fea5770a-d7de-4169-893c-eae2aa97f517"
   },
   "outputs": [],
   "source": [
    "# Initialize a git repository\n",
    "!git init\n",
    "\n",
    "# Initialize ZenML's .zen file\n",
    "!zenml init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQE8PSXDzL-_"
   },
   "source": [
    "Now, the setup is completed. For the next steps, just make sure that you are executing the code within your ZenML repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izjbDO-6yrFM"
   },
   "source": [
    "## Import relevant packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2gtj5QKCnSj0"
   },
   "source": [
    "We will use pipelines and steps in to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LvFo9epOUE7G"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import ClassifierMixin\n",
    "\n",
    "from zenml.integrations.sklearn.helpers.digits import get_digits, get_digits_model\n",
    "from zenml.pipelines import pipeline\n",
    "from zenml.steps import step\n",
    "from zenml.steps.step_output import Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6UwqjAR2yvH_"
   },
   "source": [
    "## Define ZenML Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5wHcI2FinX2O"
   },
   "source": [
    "In the code that follows, you can see that we are defining the various steps of our pipeline. Each step is decorated with `@step`, the main abstraction that is currently available for creating pipeline steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZI9i2FJ0k3H"
   },
   "source": [
    "The first step is an `importer` step that downloads a sample of the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1VT_PAW10jbp"
   },
   "outputs": [],
   "source": [
    "@step\n",
    "def importer() -> Output(\n",
    "    X_train=np.ndarray, X_test=np.ndarray, y_train=np.ndarray, y_test=np.ndarray\n",
    "):\n",
    "    \"\"\"Loads the digits array as normal numpy arrays.\"\"\"\n",
    "    X_train, X_test, y_train, y_test = get_digits()\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aU9ygH9s1BgR"
   },
   "source": [
    "Then we add a `normalizer` step that takes as input the test set and the trained model and evaluates some final metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def normalizer(\n",
    "    X_train: np.ndarray, X_test: np.ndarray\n",
    ") -> Output(X_train_normed=np.ndarray, X_test_normed=np.ndarray):\n",
    "    \"\"\"Normalize the values for all the images so they are between 0 and 1\"\"\"\n",
    "    X_train_normed = X_train / 255.0\n",
    "    X_test_normed = X_test / 255.0\n",
    "    return X_train_normed, X_test_normed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ma53mucU0yF3"
   },
   "source": [
    "We then add a `trainer` step, that takes the normalized data and trains a sklearn model on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZEw7Cbqx0wXj"
   },
   "outputs": [],
   "source": [
    "@step\n",
    "def trainer(\n",
    "    X_train: np.ndarray,\n",
    "    y_train: np.ndarray,\n",
    ") -> ClassifierMixin:\n",
    "    \"\"\"Train a simple sklearn classifier for the digits dataset.\"\"\"\n",
    "    model = get_digits_model()\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we had an `evaluator` to see how we did on the dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def evaluator(\n",
    "    X_test: np.ndarray,\n",
    "    y_test: np.ndarray,\n",
    "    model: ClassifierMixin,\n",
    ") -> float:\n",
    "    \"\"\"Calculate the accuracy on the test set\"\"\"\n",
    "    test_acc = model.score(X_test, y_test)\n",
    "    print(f\"Test accuracy: {test_acc}\")\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_iZTIz8y7Cp"
   },
   "source": [
    "## Define ZenML Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oKbU3WlbnoiA"
   },
   "source": [
    "A pipeline is defined with the `@pipeline` decorator. This defines the various steps of the pipeline and specifies the dependencies between the steps, thereby determining the order in which they will be run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rm8SIrLFWenn"
   },
   "outputs": [],
   "source": [
    "@pipeline\n",
    "def mnist_pipeline(\n",
    "    importer,\n",
    "    normalizer,\n",
    "    trainer,\n",
    "    evaluator,\n",
    "):\n",
    "    # Link all the steps together\n",
    "    X_train, X_test, y_train, y_test = importer()\n",
    "    X_trained_normed, X_test_normed = normalizer(X_train=X_train, X_test=X_test)\n",
    "    model = trainer(X_train=X_trained_normed, y_train=y_train)\n",
    "    evaluator(X_test=X_test_normed, y_test=y_test, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-JtDHu_z1IX"
   },
   "source": [
    "## Run the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NrJA5OSgnydC"
   },
   "source": [
    "Running the pipeline is as simple as calling the `run()` method on an instance of the defined pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dRzZA406UVVz",
    "outputId": "f61e4408-4001-4cc7-ed7d-8472b1c4089f"
   },
   "outputs": [],
   "source": [
    "# Initialise the pipeline\n",
    "first_pipeline = mnistpipeline(\n",
    "    importer=importer(),\n",
    "    normalizer=normalizer(),\n",
    "    trainer=trainer(),\n",
    "    evaluator=evaluator(),\n",
    ")\n",
    "\n",
    "first_pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gotkJdTQz8j2"
   },
   "source": [
    "# Transitioning to Kubeflow Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PMLU4cNW-Ei4"
   },
   "source": [
    "We got pretty good results on the MNIST model that we trained, but maybe we want to see how a similar training pipeline would work on a different dataset.\n",
    "\n",
    "You can see how easy it is to switch out one data import step and processing for another in our pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-requisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run this example, you need to have installed:\n",
    "\n",
    "* Docker\n",
    "* K3D https://k3d.io/v5.2.1/\n",
    "* Kubectl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "scikit-learn\n",
    "pandas\n",
    "numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scikit-learn', 'pandas', 'numpy']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requirements_file = os.path.join(os.path.abspath(''), \"requirements.txt\")\n",
    "with open(requirements_file, 'r') as f:\n",
    "    c = f.read()\n",
    "    \n",
    "c.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Kubeflow Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zenml container-registry register local_registry localhost:5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zenml orchestrator register kubeflow_orchestrator kubeflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zenml stack register local_kubeflow_stack -m local_metadata_store -a local_artifact_store -o kubeflow_orchestrator -c local_registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zenml stack set local_kubeflow_stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets spin the stack up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zenml stack up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the pipeline to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile run.py\n",
    "#  Copyright (c) ZenML GmbH 2021. All Rights Reserved.\n",
    "#\n",
    "#  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#  you may not use this file except in compliance with the License.\n",
    "#  You may obtain a copy of the License at:\n",
    "#\n",
    "#       http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "#  Unless required by applicable law or agreed to in writing, software\n",
    "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express\n",
    "#  or implied. See the License for the specific language governing\n",
    "#  permissions and limitations under the License.\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from zenml.pipelines import pipeline\n",
    "from zenml.steps import step\n",
    "from zenml.steps.base_step_config import BaseStepConfig\n",
    "from zenml.steps.step_output import Output\n",
    "\n",
    "# Path to a pip requirements file that contains requirements necessary to run\n",
    "# the pipeline\n",
    "requirements_file = os.path.join(os.path.dirname(__file__), \"requirements.txt\")\n",
    "\n",
    "\n",
    "class ImporterConfig(BaseStepConfig):\n",
    "    n_days: int = 1\n",
    "\n",
    "\n",
    "def get_X_y_from_api(n_days: int = 1, is_train: bool = True):\n",
    "    url = (\n",
    "        \"https://storage.googleapis.com/zenml-public-bucket/mnist\"\n",
    "        \"/mnist_handwritten_train.json\"\n",
    "        if is_train\n",
    "        else \"https://storage.googleapis.com/zenml-public-bucket/mnist\"\n",
    "        \"/mnist_handwritten_test.json\"\n",
    "    )\n",
    "    df = pd.DataFrame(requests.get(url).json())\n",
    "    X = df[\"image\"].map(lambda x: np.array(x)).values\n",
    "    X = np.array([x.reshape(28, 28) for x in X])\n",
    "    y = df[\"label\"].map(lambda y: np.array(y)).values\n",
    "    return X, y\n",
    "\n",
    "\n",
    "@step\n",
    "def importer(\n",
    "    config: ImporterConfig,\n",
    ") -> Output(\n",
    "    X_train=np.ndarray, y_train=np.ndarray, X_test=np.ndarray, y_test=np.ndarray\n",
    "):\n",
    "    \"\"\"Downloads the latest data from a mock API.\"\"\"\n",
    "    X_train, y_train = get_X_y_from_api(n_days=config.n_days, is_train=True)\n",
    "    X_test, y_test = get_X_y_from_api(n_days=config.n_days, is_train=False)\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "@step\n",
    "def normalizer(\n",
    "    X_train: np.ndarray, X_test: np.ndarray\n",
    ") -> Output(X_train_normed=np.ndarray, X_test_normed=np.ndarray):\n",
    "    \"\"\"Normalize the values for all the images so they are between 0 and 1\"\"\"\n",
    "    X_train_normed = X_train / 255.0\n",
    "    X_test_normed = X_test / 255.0\n",
    "    return X_train_normed, X_test_normed\n",
    "\n",
    "\n",
    "@step\n",
    "def trainer(\n",
    "    X_train: np.ndarray,\n",
    "    y_train: np.ndarray,\n",
    ") -> ClassifierMixin:\n",
    "    \"\"\"Train SVC from sklearn.\"\"\"\n",
    "    clf = LogisticRegression(penalty=\"l1\", solver=\"saga\", tol=0.1)\n",
    "    clf.fit(X_train.reshape((X_train.shape[0], -1)), y_train)\n",
    "    return clf\n",
    "\n",
    "\n",
    "@step\n",
    "def evaluator(\n",
    "    X_test: np.ndarray,\n",
    "    y_test: np.ndarray,\n",
    "    model: ClassifierMixin,\n",
    ") -> float:\n",
    "    \"\"\"Calculate accuracy score with classifier.\"\"\"\n",
    "    test_acc = model.score(X_test.reshape((X_test.shape[0], -1)), y_test)\n",
    "    return test_acc\n",
    "\n",
    "\n",
    "@pipeline(requirements_file=requirements_file)\n",
    "def mnistpipeline(\n",
    "    importer,\n",
    "    normalizer,\n",
    "    trainer,\n",
    "    evaluator,\n",
    "):\n",
    "    # Link all the steps together\n",
    "    X_train, y_train, X_test, y_test = importer()\n",
    "    X_trained_normed, X_test_normed = normalizer(X_train=X_train, X_test=X_test)\n",
    "    model = trainer(X_train=X_trained_normed, y_train=y_train)\n",
    "    evaluator(X_test=X_test_normed, y_test=y_test, model=model)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the pipeline\n",
    "    p = mnistpipeline(\n",
    "        importer=importer(),\n",
    "        normalizer=normalizer(),\n",
    "        trainer=trainer(),\n",
    "        evaluator=evaluator(),\n",
    "    )\n",
    "    p.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise a new pipeline\n",
    "!python run.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-uKNmljpIYRh"
   },
   "source": [
    "# Post execution workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R5yPNQ1fIYRh"
   },
   "outputs": [],
   "source": [
    "from zenml.core.repo import Repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lhG-rEDZIYRi"
   },
   "source": [
    "## Get repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_cZqhydiIYRj"
   },
   "outputs": [],
   "source": [
    "repo = Repository()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T-rao3-oIYRj"
   },
   "source": [
    "## Pipelines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZxMk-vsmIYRk"
   },
   "outputs": [],
   "source": [
    "pipelines = repo.get_pipelines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oFd--JgZIYRk"
   },
   "source": [
    "## Retrieve the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2BSbKed-IYRk"
   },
   "outputs": [],
   "source": [
    "mnist_pipeline = pipelines[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xpNKuyChIYRl"
   },
   "source": [
    "## Get the first run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jI57bWbHIYRl"
   },
   "outputs": [],
   "source": [
    "runs = mnist_pipeline.runs  # chronologically ordered\n",
    "mnist_run = runs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pIPmpQCrIYRl"
   },
   "source": [
    "## Get the second run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1SGaTPduIYRl"
   },
   "outputs": [],
   "source": [
    "fashion_mnist_run = runs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HDR1JNHtIYRm"
   },
   "source": [
    "## Get the steps (note the first step name is different)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vct_wqq1IYRm",
    "outputId": "7800431d-813b-4721-f61d-27f4012f9d2d"
   },
   "outputs": [],
   "source": [
    "mnist_run.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lnQkTAv6IYRm",
    "outputId": "8fedfaf1-b5c9-4218-809c-244b8f6ebc2c"
   },
   "outputs": [],
   "source": [
    "fashion_mnist_run.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5m6d6VPDIYRn"
   },
   "source": [
    "## Check the results of the evaluator and compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sF7YM4_iIYRn"
   },
   "outputs": [],
   "source": [
    "mnist_eval_step = mnist_run.get_step(name='evaluator')\n",
    "fashion_mnist_eval_step = fashion_mnist_run.get_step(name='evaluator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V5fvkLoZIYRn",
    "outputId": "a8d0ad4d-bbd0-4320-a282-870120ac3ddf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# One output is simply called `output`, multiple is a dict called `outputs`.\n",
    "mnist_eval_step.output.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wMBKfBSeIYRo",
    "outputId": "4387f938-bb21-492e-9c90-79a8b4329101"
   },
   "outputs": [],
   "source": [
    "fashion_mnist_eval_step.output.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Tan15BgIYRo"
   },
   "source": [
    "# Congratulations!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uOJtVVaFzlUO"
   },
   "source": [
    "… and that's it for the quickstart. If you came here without a hiccup, you must have successly installed ZenML, set up a ZenML repo, configured a training pipeline, executed it and evaluated the results. And, this is just the tip of the iceberg on the capabilities of ZenML.\n",
    "\n",
    "However, if you had a hiccup or you have some suggestions/questions regarding our framework, you can always check our [docs](https://docs.zenml.io/) or our [Github](https://github.com/zenml-io/zenml) or even better join us on our [Slack channel](https://zenml.io/slack-invite).\n",
    "\n",
    "Cheers!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "22gkBKSntlF8"
   },
   "source": [
    "For more detailed information on all the components and steps that went into this short example, please continue reading [our more detailed documentation pages](https://docs.zenml.io/)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "ZenML Quickstart.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}