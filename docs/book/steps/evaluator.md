# Evaluator
The Evaluator is executed right after [Trainer](trainer.md) step in the [TrainingPipeline](../pipelines/training-pipeline.md).
The purpose of the evaluator step is to calculate relevant metrics to accertain how well a trained model performed on 
un-seen data.

## Create custom evaluator
The mechanism to create a custom Evaluator will be published in more detail soon in this space.
However, the details of this are currently being worked out and will be made available in future releases.

If you need this functionality earlier, then ping us on our [Slack](https://zenml.io/slack-invite) or [create an issue on GitHub](https://https://github.com/maiot-io/zenml) 
so that we know about it!