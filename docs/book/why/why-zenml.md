---
description: Discuss why ZenML
---

# Why ZenML?

We built ZenML because we could not find an easy framework that translates the patterns observed in the research phase with Jupyter notebooks into a production-ready ML environment. ZenML follows the paradigm of [Pipelines of Experiments \(PaE\),](why-zenml.md#pipelines-as-experiments-pae) meaning ZenML pipelines are designed to be written early on the development lifecycle, where the users can explore their pipelines as they develop towards production.

By using ZenML at the early stages of development, you get the following features:

* **Reproducibility** of training and inference workflows.  __
* Managing ML **metadata**, including versioning data, code, and models.  
* Getting an **overview** of your ML development, with a reliable link between training and deployment.  __
* Maintaining **comparability** between ML models.  
* **Scaling** ML training/inference to large datasets.  __
* Retaining code **quality** alongside development velocity.  
* **Reusing** code/data and reducing waste. 
* Keeping up with the **ML tooling landscape** with standard abstractions and interfaces.

## Pipelines As Experiments \(PaE\)

## Development Experience \(DX\)



## The right abstractions

While there are other pipelining solutions for Machine Learning experiments, **ZenML** is focused on the following:

* Simplicity.
* Reproducibility.
* Integrations.

Why we think this is the right abstraction layer \(have to compare with others\)

Too complicated:

* Dagster
* Flyte
* Metaflow
* Prefect

Too little ops:

* MLFlow
* Kedro

## The modular MLOps stack \(Integrations\)

Integrating with others.

